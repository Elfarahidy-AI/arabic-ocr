{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import measure, filters, color\n",
    "from skimage.measure import label, regionprops\n",
    "from Utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_horizontal_projection(image):\n",
    "    return np.sum(image, axis=1)\n",
    "\n",
    "def get_vertical_projection(image):\n",
    "    return np.sum(image, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_edge_detection(image):\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    _, gray_image = cv.threshold(image, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)    \n",
    "    edges = cv.Canny(image, 100, 200)  \n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_whitespace_horizontal_projection(image_path):\n",
    "    image = cv.imread(image_path)\n",
    "    image_gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY) if len(image.shape) == 3 else image\n",
    "\n",
    "    thresh = image_gray < np.max(image_gray) * 0.70\n",
    "    thresh = thresh.astype(int)\n",
    "\n",
    "    horizontal_projection = np.sum(thresh, axis=1)\n",
    "\n",
    "    non_white_rows = np.where(horizontal_projection > 0)[0]\n",
    "\n",
    "    if non_white_rows.size:\n",
    "        start_row = non_white_rows[0]\n",
    "        end_row = non_white_rows[-1]\n",
    "        \n",
    "        cropped_image = image[start_row:end_row+1]\n",
    "    else:\n",
    "        cropped_image = image \n",
    "        \n",
    "    return cropped_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deskew_text_image(img):\n",
    "    if len(img.shape) == 3:\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "        img = cv.GaussianBlur(img, (9, 9), 0)\n",
    "\n",
    "    resized_height = 480\n",
    "    percent = resized_height / len(img)\n",
    "    resized_width = int(percent * len(img[0]))\n",
    "    \n",
    "    gray = cv.resize(img,(resized_width,resized_height))\n",
    "    \n",
    "    start_point = (0, 0) \n",
    "    end_point = (gray.shape[0], gray.shape[1]) \n",
    "    color = (255, 255, 255) \n",
    "    thickness = 10\n",
    "    gray = cv.rectangle(gray, start_point, end_point, color, thickness)\n",
    "    gray = cv.bitwise_not(gray)\n",
    " \n",
    "    thresh = cv.threshold(gray, 0, 255,\n",
    "        cv.THRESH_BINARY | cv.THRESH_OTSU)[1]\n",
    "    \n",
    "    kernel = cv.getStructuringElement(cv.MORPH_RECT, (30, 5))\n",
    "    dilate = cv.dilate(thresh, kernel)\n",
    "    \n",
    "    contours, hierarchy = cv.findContours(dilate, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    angles = []\n",
    "    for contour in contours:\n",
    "        minAreaRect = cv.minAreaRect(contour)\n",
    "        angle = minAreaRect[-1]\n",
    "        if angle != 90.0 and angle != -0.0: #filter out 0 and 90\n",
    "            angles.append(angle)\n",
    "    \n",
    "    if len(angles) == 0:\n",
    "        return img\n",
    "    \n",
    "    angles.sort()\n",
    "    mid_angle = angles[int(len(angles)/2)]    \n",
    "    \n",
    "    if angle > 45: #anti-clockwise\n",
    "        angle = -(90 - angle)\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    m = cv.getRotationMatrix2D((width / 2, height / 2), angle, 1)\n",
    "    deskewed = cv.warpAffine(img, m, (width, height), borderValue=(255,255,255))\n",
    "    \n",
    "    return deskewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_regions(edge_image):\n",
    "    binary_image = np.array(edge_image) > 128\n",
    "    label_image = label(binary_image)\n",
    "    regions = regionprops(label_image)\n",
    "\n",
    "    bounding_boxes = [region.bbox for region in regions if region.area > 50]  \n",
    "    return bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge bounding boxes that are close to each other\n",
    "def merge_bounding_boxes(bounding_boxes, proximity_threshold=10, line_height=0):\n",
    "    merged_boxes = []\n",
    "        \n",
    "    # Sort bounding boxes by their top-left x-coordinate\n",
    "    bounding_boxes.sort(key=lambda box: box[1])\n",
    "\n",
    "    for box in bounding_boxes:\n",
    "        merged = False\n",
    "        for merged_box in merged_boxes:\n",
    "            if  ((box[3] <= merged_box[1]) or (abs(box[3] - merged_box[1]) <= proximity_threshold)) and abs(box[0] - merged_box[0]) <= line_height :\n",
    "                # Merge the boxes horizontally\n",
    "                new_box = (min(merged_box[0], box[0]),  \n",
    "                           min(merged_box[1], box[1]),\n",
    "                            max(merged_box[2], box[2]),\n",
    "                           max(merged_box[3], box[3]))\n",
    "                merged_boxes.remove(merged_box)\n",
    "                merged_boxes.append(new_box)\n",
    "                merged = True\n",
    "                break\n",
    "        if not merged:\n",
    "            merged_boxes.append(box)\n",
    "    \n",
    "    return merged_boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_lines(binary_image, dots_image):\n",
    "    original_image = binary_image.copy()\n",
    "    dots_image_copy = dots_image.copy()\n",
    "    \n",
    "    horizontal_projection = get_horizontal_projection(binary_image)\n",
    "\n",
    "    line_indices = np.where(horizontal_projection > 0)[0]\n",
    "    if not line_indices.size:\n",
    "        return []  \n",
    "\n",
    "    lines = []\n",
    "    dots_lines = []\n",
    "    start_idx = line_indices[0]\n",
    "    for i in range(1, len(line_indices)):\n",
    "        if line_indices[i] - line_indices[i - 1] > 1:  # Found a gap between lines\n",
    "            end_idx = line_indices[i - 1]\n",
    "            \n",
    "            line_image = binary_image[start_idx:end_idx + 1]\n",
    "            lines.append(line_image)\n",
    "            \n",
    "            dots_line_image = dots_image[start_idx:end_idx + 1]\n",
    "            dots_lines.append(dots_line_image)\n",
    "            \n",
    "            start_idx = line_indices[i]\n",
    "            #draw the bounding box of the line on the binary image\n",
    "            original_image = cv.rectangle(original_image, (0, start_idx), (original_image.shape[1], end_idx), (255, 255, 255), 2)\n",
    "\n",
    "    # Add the last line\n",
    "    if start_idx <= line_indices[-1]:\n",
    "        end_idx = line_indices[-1]\n",
    "        \n",
    "        line_image = binary_image[start_idx:end_idx + 1]\n",
    "        lines.append(line_image)\n",
    "        \n",
    "        dots_line_image = dots_image[start_idx:end_idx + 1]\n",
    "        dots_lines.append(dots_line_image)\n",
    "        \n",
    "        #draw the bounding box of the line on the binary image\n",
    "        original_image = cv.rectangle(original_image, (0, start_idx), (original_image.shape[1], end_idx), (255, 255, 255), 2)\n",
    "\n",
    "    \n",
    "    # Create a list of indices where lines are not empty\n",
    "    indices_to_keep = [i for i, line in enumerate(lines) if np.sum(line) > 0]\n",
    "\n",
    "    # Filter both dots_lines and lines using the indices_to_keep\n",
    "    dots_lines = [dots_lines[i] for i in indices_to_keep]\n",
    "    lines = [lines[i] for i in indices_to_keep]\n",
    "\n",
    "    return lines, dots_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_line_height(lines):\n",
    "    line_heights = []\n",
    "    for line in lines:\n",
    "        line_heights.append(line.shape[0])\n",
    "        \n",
    "    mean = np.mean(line_heights)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proximity_threshold(line):\n",
    "    if len(line.shape) == 3:\n",
    "        line = cv.cvtColor(line, cv.COLOR_BGR2GRAY)\n",
    "    _, binary_image = cv.threshold(line, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)\n",
    "    \n",
    "    \n",
    "    # Compute vertical projection\n",
    "    vertical_projection = get_vertical_projection(binary_image)\n",
    "\n",
    "    gap_indices = np.where(vertical_projection == 0)[0]\n",
    "    if gap_indices.size <= 1:\n",
    "        #get the minimum values of the vertical projection\n",
    "        min_vertical_projection = np.min(vertical_projection)\n",
    "        gap_indices = np.where(vertical_projection == min_vertical_projection)[0]\n",
    "        \n",
    "    gap_widths = np.diff(gap_indices)\n",
    "   \n",
    "    #remove extreme high outliers\n",
    "    gap_widths = gap_widths[gap_widths < np.percentile(gap_widths, 90)]\n",
    "\n",
    "    # set proximity threshold to upper median of gap widths\n",
    "    proximity_threshold = abs(np.median(gap_widths) - np.std(gap_widths))\n",
    "    \n",
    "    return proximity_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial_words(lines, line_height):\n",
    "    for i, line in enumerate(lines):\n",
    "        #save_words([line], 'line_' + str(i), 'D:/UNI/CCE_sem_8_LAST_YAY_^^/gp2/project/graduation_project-Ocr_module/trial_lines')\n",
    "        if np.all(line == 0):\n",
    "            continue        \n",
    "            \n",
    "        edge_image = canny_edge_detection(line)\n",
    "        show_images([edge_image], ['Edge Image'])\n",
    "        \n",
    "        bounding_boxes = extract_text_regions(edge_image)\n",
    "        \n",
    "        proximity_threshold = get_proximity_threshold(line)\n",
    "        \n",
    "        merged_boxes = merge_bounding_boxes(bounding_boxes, proximity_threshold, line_height)\n",
    "        \n",
    "        plot_text_regions(line, merged_boxes)\n",
    "        \n",
    "        words = [line[0:line.shape[1], box[1]:box[3]] for box in merged_boxes]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_words(words, file_name, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    for i, word in enumerate(words):\n",
    "        cv.imwrite(f'{output_dir}/{file_name}_word_{i}.png', word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_lines(lines, average_height, dots_lines):\n",
    "    new_lines = []\n",
    "    new_dots_lines = []\n",
    "    for i, line in enumerate(lines):\n",
    "        dots_line = dots_lines[i]\n",
    "        if line.shape[0] > average_height * 2:\n",
    "            lines.pop(i)\n",
    "            dots_lines.pop(i)           \n",
    "             \n",
    "            deskewed_line = deskew_text_image(line)           \n",
    "            horizontal_proj = get_horizontal_projection(deskewed_line)\n",
    "    \n",
    "            #min peaks is the smallest 10% of the peaks\n",
    "            threshhold = np.percentile(horizontal_proj, 10)\n",
    "            min_peaks = horizontal_proj[horizontal_proj <= threshhold]\n",
    "            min_peaks_indices = [i for i, peak in enumerate(horizontal_proj) if peak in min_peaks]\n",
    "            #if there are conitnuous min peaks, get the median of the conitnuous peaks\n",
    "            cont_array =[]\n",
    "            new_min_peaks_indices = []\n",
    "            for j in range(1, len(min_peaks_indices)):\n",
    "                if min_peaks_indices[j] - min_peaks_indices[j-1] == 1:\n",
    "                    cont_array.append(min_peaks_indices[j-1])\n",
    "                    cont_array.append(min_peaks_indices[j])\n",
    "                else:\n",
    "                    if len(cont_array) > 0:\n",
    "                        median = np.median(cont_array)\n",
    "                        #remove all the continuous indices and add the median\n",
    "                        new_min_peaks_indices.append(median)\n",
    "                        cont_array = []\n",
    "                    else:\n",
    "                        new_min_peaks_indices.append(min_peaks_indices[j-1])\n",
    "                    \n",
    "            resplit_lines = []\n",
    "            resplit_dots_lines = []\n",
    "            if len(min_peaks_indices) == 0:\n",
    "                continue\n",
    "            elif len(min_peaks_indices) == 1:\n",
    "                split_index = min_peaks_indices[0]\n",
    "                resplit_lines.append(deskewed_line[:split_index, :])\n",
    "                resplit_dots_lines.append(dots_line[:split_index, :])\n",
    "                \n",
    "                resplit_lines.append(deskewed_line[split_index:, :])\n",
    "                resplit_dots_lines.append(dots_line[split_index:, :])\n",
    "            else:\n",
    "                resplit_lines.append(deskewed_line[:min_peaks_indices[0], :])\n",
    "                resplit_dots_lines.append(dots_line[:min_peaks_indices[0], :])\n",
    "                \n",
    "                for i, split_index in enumerate(min_peaks_indices):\n",
    "                    if i == len(min_peaks_indices) -1:\n",
    "                        resplit_lines.append(deskewed_line[split_index:, :])\n",
    "                        resplit_dots_lines.append(dots_line[split_index:, :])\n",
    "                    else:\n",
    "                        resplit_lines.append(deskewed_line[split_index: min_peaks_indices[i+1], :])\n",
    "                        resplit_dots_lines.append(dots_line[split_index: min_peaks_indices[i+1], :])\n",
    "                        \n",
    "            new_lines.extend(resplit_lines)\n",
    "            new_dots_lines.extend(resplit_dots_lines)\n",
    "        else:\n",
    "            new_lines.append(line)\n",
    "            new_dots_lines.append(dots_line)\n",
    "    \n",
    "    # Create a list of indices where lines are not empty\n",
    "    indices_to_keep = [i for i, line in enumerate(new_lines) if line.shape[0] > 10]\n",
    "\n",
    "    # Filter both dots_lines and lines using the indices_to_keep\n",
    "    new_dots_lines = [new_dots_lines[i] for i in indices_to_keep]\n",
    "    new_lines = [new_lines[i] for i in indices_to_keep]\n",
    "    \n",
    "    return new_lines, new_dots_lines\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_zero_segments(vertical_projection):\n",
    "    zero_segments = []\n",
    "    in_zero_segment = False\n",
    "    start_index = None\n",
    "    \n",
    "    for i, value in enumerate(vertical_projection):\n",
    "        if value == 0:\n",
    "            if not in_zero_segment:\n",
    "                in_zero_segment = True\n",
    "                start_index = i\n",
    "        else:\n",
    "            if in_zero_segment:\n",
    "                # We're exiting a zero segment\n",
    "                zero_segments.append((start_index, i - 1))\n",
    "                in_zero_segment = False\n",
    "\n",
    "    # Check if the last segment in the array was a zero segment\n",
    "    if in_zero_segment:\n",
    "        zero_segments.append((start_index, len(vertical_projection) - 1))\n",
    "    \n",
    "    return zero_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words_from_segments(vertically_cropped_line, filtered_areas):\n",
    "    words = []\n",
    "    bounding_boxes = []\n",
    "    \n",
    "    #append the first word\n",
    "    first_word = vertically_cropped_line[:, :filtered_areas[0][0]]    \n",
    "    words.append(first_word)\n",
    "    bounding_boxes.append((0, 0, filtered_areas[0][0], vertically_cropped_line.shape[0]))\n",
    "    \n",
    "    for i in range(len(filtered_areas) - 1):\n",
    "        # Get the end index of the current segment and the start index of the next segment\n",
    "        current_end = filtered_areas[i][1]\n",
    "        next_start = filtered_areas[i + 1][0]\n",
    "        \n",
    "        # Extract the part of the image between these indices\n",
    "        word = vertically_cropped_line[:, current_end:next_start]\n",
    "        bounding_boxes.append((current_end, 0, next_start, vertically_cropped_line.shape[0]))\n",
    "        words.append(word)\n",
    "        \n",
    "    \n",
    "    #append the last word\n",
    "    last_word = vertically_cropped_line[:, filtered_areas[-1][1]:]\n",
    "    words.append(last_word)\n",
    "    bounding_boxes.append((filtered_areas[-1][1], 0, vertically_cropped_line.shape[1], vertically_cropped_line.shape[0]))\n",
    "    \n",
    "    #make sure none of the words is all black pixels\n",
    "    words = [word for word in words if np.sum(word) > 0]\n",
    "    return words, bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contours(image):\n",
    "    return cv.findContours(image, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_contours(image, contours):\n",
    "    percntile_40 = np.percentile([cv.contourArea(contour) for contour in contours], 30)\n",
    "    #get contours that are too small\n",
    "    small_contours = [contour for contour in contours if cv.contourArea(contour) < percntile_40]\n",
    "    new_image = np.zeros_like(image)\n",
    "    #fill the small contours with black\n",
    "    for contour in small_contours:\n",
    "        #remove the small contours by filling them with black\n",
    "        image = cv.drawContours(image, [contour], 0, (0, 0, 0), -1)\n",
    "        #add the removed contours to a new image\n",
    "        dots_image = cv.drawContours(new_image, [contour], 0, (250, 250, 250), 3)        \n",
    "    return image, dots_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(path):\n",
    "    original_image = crop_whitespace_horizontal_projection(path)\n",
    "    \n",
    "    #opening\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_RECT, (3,3))\n",
    "    image = cv.morphologyEx(original_image, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "    #closing\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_RECT, (3,3))\n",
    "    image = cv.morphologyEx(original_image, cv.MORPH_CLOSE, kernel)\n",
    "\n",
    "    #opening\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_RECT, (3,3))\n",
    "    image = cv.morphologyEx(original_image, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    _, binary_image = cv.threshold(image, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)\n",
    "\n",
    "    contours = get_contours(binary_image)\n",
    "\n",
    "    binary_image_filled, dots_image = fill_contours(binary_image, contours)\n",
    "\n",
    "    lines, dots_lines = segment_lines(binary_image_filled, dots_image)\n",
    "    \n",
    "    #remove lines that are too small\n",
    "    dots_lines = [dots_line for dots_line, line in zip(dots_lines, lines) if line.shape[0] > 20]  # Remove empty lines\n",
    "    lines = [line for line in lines if line.shape[0] > 20]\n",
    "    \n",
    "    line_height = get_average_line_height(lines)\n",
    "        \n",
    "    lines, dots_lines = process_lines(lines, line_height, dots_lines)\n",
    "    \n",
    "    output = []\n",
    "    for i, line in enumerate(lines):\n",
    "        vertical_projection = get_vertical_projection(line)\n",
    "        \n",
    "        vertically_cropped_line = line\n",
    "        \n",
    "        #check if the image starts and ends with black space, if so remove that part of the line\n",
    "        if vertical_projection[0] == 0:\n",
    "            #get the first index where the value is not 0\n",
    "            start_index = np.where(vertical_projection != 0)[0][0]\n",
    "            vertically_cropped_line = line[:, start_index:]\n",
    "            dots_lines[i] = dots_lines[i][:, start_index:]\n",
    "            vertical_projection = get_vertical_projection(vertically_cropped_line)\n",
    "            \n",
    "        zero_segments = find_zero_segments(vertical_projection)\n",
    "        average_area = np.mean([end - start for start, end in zero_segments])\n",
    "    \n",
    "        filtered_areas = [(start , end) for start, end in zero_segments if end - start > average_area or end - start > 0.65 * average_area]\n",
    "        \n",
    "        words, word_box = extract_words_from_segments(vertically_cropped_line, filtered_areas)    \n",
    "        \n",
    "        vertically_cropped_line = cv.bitwise_or(vertically_cropped_line, dots_lines[i])\n",
    "        \n",
    "        #extract the words bounded by the boxes from vertically cropped line into a new list of words\n",
    "        new_words = [vertically_cropped_line[:, box[0]:box[2]] for box in word_box]\n",
    "        new_words = [word for word in new_words if np.sum(word) > 0]\n",
    "        \n",
    "        output.append((vertically_cropped_line, new_words))\n",
    "    return output\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_save_lines_words(path):\n",
    "\n",
    "    segmented_picture = segment(path)\n",
    "    \n",
    "    return segmented_picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'D:/UNI/CCE_sem_8_LAST_YAY_^^/gp2/project/Alfarahifi_org/arabic-ocr/paragraphs_per_user/paragraphs_per_user/user001/com_paragraph.png'\n",
    "\n",
    "# segment_save_lines_words(path, '0', '001')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
