{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding(original_image, padding = 10):\n",
    "    original_image = cv.copyMakeBorder(original_image, padding, padding, padding, padding, cv.BORDER_CONSTANT, value=0)\n",
    "    \n",
    "    return original_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opening(original_image):\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_RECT, (3, 3))\n",
    "    word = cv.morphologyEx(original_image, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closing(original_image):\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_RECT, (3, 3))\n",
    "    word = cv.morphologyEx(original_image, cv.MORPH_CLOSE, kernel)\n",
    "\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contours(word):\n",
    "    contours, _ = cv.findContours(word, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_holes(contours, word):\n",
    "    max_area = np.max([cv.contourArea(contour) for contour in contours])\n",
    "    #remove contours that are too small\n",
    "    small_contours = [contour for contour in contours if cv.contourArea(contour) < max_area * 0.1]\n",
    "    #fill the small contours Wwith black\n",
    "    for contour in small_contours:\n",
    "        word = cv.drawContours(word, [contour], 0, (0, 0, 0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_horizontal_projection(word):\n",
    "    horizontal_projection = np.sum(word, axis=1)\n",
    "    return horizontal_projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_value_in_hp(horizontal_projection):\n",
    "    max_value_horizontal_proj = np.max(horizontal_projection)\n",
    "    max_index_global_horizontal = np.where(horizontal_projection == max_value_horizontal_proj)[0][0]\n",
    "    return max_value_horizontal_proj, max_index_global_horizontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_minimas_horizontal(horizontal_projection):\n",
    "    local_minimas_horizontal = []\n",
    "    for i in range(1, len(horizontal_projection) - 1):\n",
    "        if horizontal_projection[i] > 0 and horizontal_projection[i - 1] == 0:\n",
    "            local_minimas_horizontal.append(i)\n",
    "\n",
    "        elif horizontal_projection[i] == 0 and horizontal_projection[i - 1] > 0:\n",
    "            local_minimas_horizontal.append(i)\n",
    "            \n",
    "    return local_minimas_horizontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_local_minimas(local_minimas_horizontal):\n",
    "    if len(local_minimas_horizontal) > 2:\n",
    "        max_diff = 0\n",
    "        max_diff_index = 0\n",
    "        for i in range(1, len(local_minimas_horizontal)):\n",
    "            diff = local_minimas_horizontal[i] - local_minimas_horizontal[i-1]\n",
    "            if diff > max_diff:\n",
    "                max_diff = diff\n",
    "                max_diff_index = i\n",
    "\n",
    "        fitered_local_minimas = [local_minimas_horizontal[max_diff_index - 1], local_minimas_horizontal[max_diff_index]]\n",
    "    else:\n",
    "        fitered_local_minimas = local_minimas_horizontal\n",
    "    return fitered_local_minimas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_no_text_areas(word, filtered_local_minimas):\n",
    "    min_local_minima = min(filtered_local_minimas)\n",
    "    max_local_minima = max(filtered_local_minimas)\n",
    "\n",
    "    #fill the area below the min local minima with black\n",
    "    word[:min_local_minima] = 0\n",
    "    #fill the area above the max local minima with black\n",
    "    word[max_local_minima:] = 0\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_top_and_bottom(fitered_local_minimas, max_index_global_horizontal):\n",
    "    text_top_height = min(fitered_local_minimas) - max_index_global_horizontal\n",
    "    text_bottom_height = max(fitered_local_minimas) - max_index_global_horizontal\n",
    "    return text_top_height, text_bottom_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vertical_projection(word):\n",
    "    vertical_projection = np.sum(word, axis=0)\n",
    "    return vertical_projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_local_minimas_in_vp(vertical_projection):\n",
    "    local_minimas = []\n",
    "    for i in range(1, len(vertical_projection) - 1):\n",
    "        if vertical_projection[i] <= vertical_projection[i - 1] and vertical_projection[i] <= vertical_projection[i + 1]:\n",
    "            local_minimas.append(i)\n",
    "    return local_minimas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_stable_regions(projection, threshold=500):\n",
    "    derivative = np.diff(projection)\n",
    "    \n",
    "    stable_indices = np.where(np.abs(derivative) < threshold)[0]\n",
    "    \n",
    "    if len(stable_indices) == 0:\n",
    "        return []\n",
    "\n",
    "    regions = []\n",
    "    start = stable_indices[0]\n",
    "\n",
    "    for i in range(1, len(stable_indices)):\n",
    "        if stable_indices[i] != stable_indices[i - 1] + 1:\n",
    "            regions.append((start, stable_indices[i - 1]))\n",
    "            start = stable_indices[i]\n",
    "    \n",
    "    regions.append((start, stable_indices[-1]))\n",
    "    \n",
    "    return regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_values(vertical_projection, stable_areas):\n",
    "    average_values = []\n",
    "    for start, end in stable_areas:\n",
    "        average_values.append(np.mean(vertical_projection[start:end]))\n",
    "    return average_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_stable_areas(stable_areas, width, average_values):\n",
    "    merged_areas = []\n",
    "    threshold = width * 0.03\n",
    "    if len(stable_areas) == 0:\n",
    "        return merged_areas\n",
    "\n",
    "    start, end = stable_areas[0]\n",
    "    \n",
    "    for i in range(1, len(stable_areas)):\n",
    "        next_start, next_end = stable_areas[i]\n",
    "        if next_start - end <= threshold and np.abs(average_values[i] - average_values[i - 1]) <= 500:\n",
    "            end = next_end\n",
    "        else:\n",
    "            merged_areas.append((start, end))\n",
    "            start, end = next_start, next_end\n",
    "    \n",
    "    merged_areas.append((start, end))\n",
    "    \n",
    "    return merged_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_small_areas(merged_areas, width):\n",
    "    merged_areas = [area for area in merged_areas if area[1] - area[0] > width * 0.005]\n",
    "    return merged_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_value_of_merged_areas(merged_areas, vertical_projection):\n",
    "    avg_values = []\n",
    "    for start, end in merged_areas:\n",
    "        avg_values.append(np.mean(vertical_projection[start:end]))\n",
    "    return avg_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_too_high_vp(average_values_merged, merged_areas):\n",
    "    filtered_areas = []\n",
    "    for i, value in enumerate(average_values_merged):\n",
    "        if value < np.percentile(average_values_merged, 80):\n",
    "            filtered_areas.append(merged_areas[i])\n",
    "    return filtered_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_text_line(skeleton_image_for_use_here, filtered_areas, text_top_height, max_index_global_horizontal, text_bottom_height, word):\n",
    "    filtered = []\n",
    "    empty_areas = []\n",
    "    for start, end in filtered_areas:\n",
    "        mid = (start + end) // 2\n",
    "        text_slice = skeleton_image_for_use_here[:, mid]\n",
    "        text_indices = np.where(text_slice == 255)[0]\n",
    "        if len(text_indices) == 0:\n",
    "            empty_areas.append((start, end))\n",
    "            continue\n",
    "\n",
    "        if np.any(np.diff(text_indices) > 1):\n",
    "            continue\n",
    "        \n",
    "        max_text_index = np.max(text_indices)\n",
    "        min_text_index = np.min(text_indices)\n",
    "        \n",
    "        if max_text_index > max_index_global_horizontal + 0.4 * abs(text_top_height) or min_text_index < max_index_global_horizontal - 0.4 * text_bottom_height:\n",
    "            continue\n",
    "        else:\n",
    "            filtered.append((start, end))\n",
    "\n",
    "    #check if empty areras falls within the text or at the start and begining only\n",
    "    for start, end in empty_areas:\n",
    "        #check if there is white pixel from start of image to the start of the empty area or from the end of the empty area to the end of the image\n",
    "        if np.any(word[:, :start] == 255) and np.any(word[:, end:] == 255):\n",
    "            filtered.append((start, end))\n",
    "    return filtered, empty_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_distances(filtered):\n",
    "    #get average distance between each consecutive area\n",
    "    filtered = sorted(filtered, key=lambda x: x[0])\n",
    "    distances = [filtered[i][0] - filtered[i - 1][0] for i in range(1, len(filtered))]\n",
    "    avg_distance = np.mean(distances)\n",
    "\n",
    "    filtered_by_distance = []\n",
    "    for start, end in filtered:\n",
    "        if filtered_by_distance and start - filtered_by_distance[-1][1] < avg_distance * 0.2:\n",
    "            # If the start of the current interval is close to the end of the last interval in the list, merge them\n",
    "            filtered_by_distance[-1] = (filtered_by_distance[-1][0], max(end, filtered_by_distance[-1][1]))\n",
    "        else:\n",
    "            # If not, add the current interval to the list\n",
    "            filtered_by_distance.append((start, end))\n",
    "    return filtered_by_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_points(filtered_by_distance, vertical_projection):\n",
    "    split_points = []\n",
    "    for start, end in filtered_by_distance:\n",
    "        min_value = np.min(vertical_projection[start:end])\n",
    "        min_index = np.where(vertical_projection[start:end] == min_value)[0][0] + start\n",
    "        split_points.append(min_index)\n",
    "    return split_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_characters(path):\n",
    "    original_image = cv.imread(path, cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "    original_image = add_padding(original_image)\n",
    "\n",
    "    word = opening(original_image)\n",
    "\n",
    "    word = closing(original_image)\n",
    "\n",
    "    word = opening(original_image)\n",
    "    \n",
    "    contours = get_contours(word)\n",
    "    \n",
    "    fill_holes(contours, word)\n",
    "\n",
    "    horizontal_projection = get_horizontal_projection(word)\n",
    "\n",
    "    max_value_horizontal_proj, max_index_global_horizontal = get_max_value_in_hp(horizontal_projection)\n",
    "\n",
    "    local_minimas_horizontal = get_local_minimas_horizontal(horizontal_projection)\n",
    "\n",
    "    filtered_local_minimas = filter_local_minimas(local_minimas_horizontal)\n",
    "\n",
    "    word = fill_no_text_areas(word, filtered_local_minimas)\n",
    "\n",
    "    text_top_height, text_bottom_height = get_text_top_and_bottom(filtered_local_minimas, max_index_global_horizontal)\n",
    "\n",
    "    vertical_projection = get_vertical_projection(word)\n",
    "\n",
    "    local_minimas  = find_local_minimas_in_vp(vertical_projection)\n",
    "\n",
    "    stable_areas = detect_stable_regions(vertical_projection)\n",
    "\n",
    "    average_values = get_average_values(vertical_projection, stable_areas)\n",
    "    \n",
    "    merged_areas = merge_stable_areas(stable_areas, word.shape[1], average_values)\n",
    "\n",
    "    height, width = word.shape\n",
    "\n",
    "    merged_areas = filter_small_areas(merged_areas, width)\n",
    "\n",
    "    average_values_merged = get_avg_value_of_merged_areas(merged_areas, vertical_projection)\n",
    "\n",
    "    filtered_areas = filter_too_high_vp(average_values_merged, merged_areas)\n",
    "\n",
    "    skeleton = skeletonize(word)\n",
    "    skeleton_image = np.where(skeleton, 255, 0).astype(np.uint8)\n",
    "    \n",
    "    filtered, empty_areas = filter_by_text_line(skeleton_image, filtered_areas, text_top_height, max_index_global_horizontal, text_bottom_height, word)\n",
    "\n",
    "    filtered_by_distance = filter_by_distances(filtered)\n",
    "    \n",
    "    split_points = get_split_points(filtered_by_distance, vertical_projection)\n",
    "\n",
    "    \n",
    "    if len(split_points) == 0:\n",
    "        return [original_image]\n",
    "\n",
    "    words = []\n",
    "    words.append(original_image[:, :split_points[0]])\n",
    "    for i in range(len(split_points) - 1):\n",
    "        words.append(original_image[:, split_points[i]:split_points[i + 1]])\n",
    "    words.append(original_image[:, split_points[-1]:])\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_characters(words):\n",
    "    if len(words) == 1 or len(words) == 0:\n",
    "        return words\n",
    "    filtered_words = []\n",
    "    average_width = np.mean([word.shape[1] for word in words])\n",
    "    for word in words:\n",
    "        height, width = word.shape\n",
    "        if width < average_width * 0.5:\n",
    "            #check amount of white pixels in the word\n",
    "            white_pixels = np.sum(word == 255)\n",
    "\n",
    "            if white_pixels / (height * width) <= 0.15:\n",
    "                continue\n",
    "        filtered_words.append(word)\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'D:/UNI/CCE_sem_8_LAST_YAY_^^/gp2/project/Alfarahifi_org/arabic-ocr/Trial/computer_par/line_0/word_1.png'\n",
    "\n",
    "# words = segment_characters(path)\n",
    "\n",
    "\n",
    "# filtered_words = filter_characters(words)\n",
    "\n",
    "# show_images(words)\n",
    "# show_images(filtered_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
