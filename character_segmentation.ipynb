{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding(original_image, padding = 10):\n",
    "    original_image = cv.copyMakeBorder(original_image, padding, padding, padding, padding, cv.BORDER_CONSTANT, value=0)\n",
    "    \n",
    "    return original_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opening(original_image):\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_RECT, (3, 3))\n",
    "    word = cv.morphologyEx(original_image, cv.MORPH_OPEN, kernel)\n",
    "\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closing(original_image):\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_RECT, (3, 3))\n",
    "    word = cv.morphologyEx(original_image, cv.MORPH_CLOSE, kernel)\n",
    "\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contours(word):\n",
    "    contours, _ = cv.findContours(word, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_holes(contours, word):\n",
    "    max_area = np.max([cv.contourArea(contour) for contour in contours])\n",
    "    #remove contours that are too small\n",
    "    small_contours = [contour for contour in contours if cv.contourArea(contour) < max_area * 0.1]\n",
    "    #fill the small contours Wwith black\n",
    "    for contour in small_contours:\n",
    "        word = cv.drawContours(word, [contour], 0, (0, 0, 0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_horizontal_projection(word):\n",
    "    horizontal_projection = np.sum(word, axis=1)\n",
    "    return horizontal_projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_value_in_hp(horizontal_projection):\n",
    "    max_value_horizontal_proj = np.max(horizontal_projection)\n",
    "    max_index_global_horizontal = np.where(horizontal_projection == max_value_horizontal_proj)[0][0]\n",
    "    return max_value_horizontal_proj, max_index_global_horizontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_minimas_horizontal(horizontal_projection):\n",
    "    local_minimas_horizontal = []\n",
    "    for i in range(1, len(horizontal_projection) - 1):\n",
    "        if horizontal_projection[i] > 0 and horizontal_projection[i - 1] == 0:\n",
    "            local_minimas_horizontal.append(i)\n",
    "\n",
    "        elif horizontal_projection[i] == 0 and horizontal_projection[i - 1] > 0:\n",
    "            local_minimas_horizontal.append(i)\n",
    "            \n",
    "    return local_minimas_horizontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_local_minimas(local_minimas_horizontal):\n",
    "    if len(local_minimas_horizontal) > 2:\n",
    "        max_diff = 0\n",
    "        max_diff_index = 0\n",
    "        for i in range(1, len(local_minimas_horizontal)):\n",
    "            diff = local_minimas_horizontal[i] - local_minimas_horizontal[i-1]\n",
    "            if diff > max_diff:\n",
    "                max_diff = diff\n",
    "                max_diff_index = i\n",
    "\n",
    "        fitered_local_minimas = [local_minimas_horizontal[max_diff_index - 1], local_minimas_horizontal[max_diff_index]]\n",
    "    else:\n",
    "        fitered_local_minimas = local_minimas_horizontal\n",
    "    return fitered_local_minimas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_no_text_areas(word, filtered_local_minimas):\n",
    "    min_local_minima = min(filtered_local_minimas)\n",
    "    max_local_minima = max(filtered_local_minimas)\n",
    "\n",
    "    #fill the area below the min local minima with black\n",
    "    word[:min_local_minima] = 0\n",
    "    #fill the area above the max local minima with black\n",
    "    word[max_local_minima:] = 0\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_top_and_bottom(fitered_local_minimas, max_index_global_horizontal):\n",
    "    text_top_height = min(fitered_local_minimas) - max_index_global_horizontal\n",
    "    text_bottom_height = max(fitered_local_minimas) - max_index_global_horizontal\n",
    "    return text_top_height, text_bottom_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vertical_projection(word):\n",
    "    vertical_projection = np.sum(word, axis=0)\n",
    "    return vertical_projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_local_minimas_in_vp(vertical_projection):\n",
    "    local_minimas = []\n",
    "    for i in range(1, len(vertical_projection) - 1):\n",
    "        if vertical_projection[i] <= vertical_projection[i - 1] and vertical_projection[i] <= vertical_projection[i + 1]:\n",
    "            local_minimas.append(i)\n",
    "    return local_minimas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_stable_regions(projection, threshold=500):\n",
    "    derivative = np.diff(projection)\n",
    "    \n",
    "    stable_indices = np.where(np.abs(derivative) < threshold)[0]\n",
    "    \n",
    "    if len(stable_indices) == 0:\n",
    "        return []\n",
    "\n",
    "    regions = []\n",
    "    start = stable_indices[0]\n",
    "\n",
    "    for i in range(1, len(stable_indices)):\n",
    "        if stable_indices[i] != stable_indices[i - 1] + 1:\n",
    "            regions.append((start, stable_indices[i - 1]))\n",
    "            start = stable_indices[i]\n",
    "    \n",
    "    regions.append((start, stable_indices[-1]))\n",
    "    \n",
    "    return regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_values(vertical_projection, stable_areas):\n",
    "    average_values = []\n",
    "    for start, end in stable_areas:\n",
    "        average_values.append(np.mean(vertical_projection[start:end]))\n",
    "    return average_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_stable_areas(stable_areas, width, average_values):\n",
    "    merged_areas = []\n",
    "    threshold = width * 0.03\n",
    "    if len(stable_areas) == 0:\n",
    "        return merged_areas\n",
    "\n",
    "    start, end = stable_areas[0]\n",
    "    \n",
    "    for i in range(1, len(stable_areas)):\n",
    "        next_start, next_end = stable_areas[i]\n",
    "        if next_start - end <= threshold and np.abs(average_values[i] - average_values[i - 1]) <= 500:\n",
    "            end = next_end\n",
    "        else:\n",
    "            merged_areas.append((start, end))\n",
    "            start, end = next_start, next_end\n",
    "    \n",
    "    merged_areas.append((start, end))\n",
    "    \n",
    "    return merged_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_small_areas(merged_areas, width):\n",
    "    merged_areas = [area for area in merged_areas if area[1] - area[0] > width * 0.005]\n",
    "    return merged_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_value_of_merged_areas(merged_areas, vertical_projection):\n",
    "    avg_values = []\n",
    "    for start, end in merged_areas:\n",
    "        avg_values.append(np.mean(vertical_projection[start:end]))\n",
    "    return avg_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_too_high_vp(average_values_merged, merged_areas):\n",
    "    filtered_areas = []\n",
    "    for i, value in enumerate(average_values_merged):\n",
    "        if value < np.percentile(average_values_merged, 80):\n",
    "            filtered_areas.append(merged_areas[i])\n",
    "    return filtered_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_text_line(skeleton_image_for_use_here, filtered_areas, text_top_height, max_index_global_horizontal, text_bottom_height, word):\n",
    "    filtered = []\n",
    "    empty_areas = []\n",
    "    #get the average positions of white pixels that fall inside each area\n",
    "    top_height_allowance = (text_top_height - max_index_global_horizontal)  * 0.5\n",
    "    bottom_height = (text_bottom_height - max_index_global_horizontal) * 0.5\n",
    "\n",
    "    for start, end in filtered_areas:\n",
    "        mid = (start + end) // 2\n",
    "        text_slice = skeleton_image_for_use_here[:, mid]\n",
    "        text_indices = np.where(text_slice == 255)[0]\n",
    "        if len(text_indices) == 0:\n",
    "            empty_areas.append((start, end))\n",
    "            continue\n",
    "        #if there is a difference between each consecutive text indices that is more than 1, then the text is not continuous\n",
    "        if np.any(np.diff(text_indices) > 1):\n",
    "            continue\n",
    "        \n",
    "        #average_text_index = np.mean(text_indices)\n",
    "        max_text_index = np.max(text_indices)\n",
    "        min_text_index = np.min(text_indices)\n",
    "        \n",
    "        if max_text_index > max_index_global_horizontal + 0.4 * abs(text_top_height) or min_text_index < max_index_global_horizontal - 0.4 * text_bottom_height:\n",
    "            continue\n",
    "        else:\n",
    "            filtered.append((start, end))\n",
    "        # if average_text_index == max_index_global_horizontal or average_text_index - max_index_global_horizontal < max_index_global_horizontal + top_height_allowance or max_index_global_horizontal - average_text_index > max_index_global_horizontal + bottom_height:\n",
    "        #     filtered.append((start, end))\n",
    "\n",
    "    #check if empty areras falls within the text or at the start and begining only\n",
    "    for start, end in empty_areas:\n",
    "        #check if there is white pixel from start of image to the start of the empty area or from the end of the empty area to the end of the image\n",
    "        if np.any(word[:, :start] == 255) and np.any(word[:, end:] == 255):\n",
    "            filtered.append((start, end))\n",
    "    return filtered, empty_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_distances(filtered):\n",
    "    #get average distance between each consecutive area\n",
    "    filtered = sorted(filtered, key=lambda x: x[0])\n",
    "    distances = [filtered[i][0] - filtered[i - 1][0] for i in range(1, len(filtered))]\n",
    "    avg_distance = np.mean(distances)\n",
    "\n",
    "    filtered_by_distance = []\n",
    "    for start, end in filtered:\n",
    "        if filtered_by_distance and start - filtered_by_distance[-1][1] < avg_distance * 0.2:\n",
    "            # If the start of the current interval is close to the end of the last interval in the list, merge them\n",
    "            filtered_by_distance[-1] = (filtered_by_distance[-1][0], max(end, filtered_by_distance[-1][1]))\n",
    "        else:\n",
    "            # If not, add the current interval to the list\n",
    "            filtered_by_distance.append((start, end))\n",
    "    return filtered_by_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_points(filtered_by_distance, vertical_projection):\n",
    "    split_points = []\n",
    "    for start, end in filtered_by_distance:\n",
    "        min_value = np.min(vertical_projection[start:end])\n",
    "        min_index = np.where(vertical_projection[start:end] == min_value)[0][0] + start\n",
    "        split_points.append(min_index)\n",
    "    return split_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_characters(path):\n",
    "    original_image = cv.imread(path, cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "    original_image = add_padding(original_image)\n",
    "\n",
    "    word = opening(original_image)\n",
    "\n",
    "    word = closing(original_image)\n",
    "\n",
    "    word = opening(original_image)\n",
    "\n",
    "    show_images([original_image, word], [\"Original Image\", \"Preprocessed Image\"])\n",
    "    \n",
    "    contours = get_contours(word)\n",
    "    \n",
    "    fill_holes(contours, word)\n",
    "    show_images([original_image, word], [\"Original Image\", \"Filled Holes Image\"])\n",
    "\n",
    "    horizontal_projection = get_horizontal_projection(word)\n",
    "\n",
    "    max_value_horizontal_proj, max_index_global_horizontal = get_max_value_in_hp(horizontal_projection)\n",
    "    \n",
    "    #draw a line at the max_index_global_horizontal to show the text line\n",
    "    image_copy_6 = word.copy()\n",
    "    image_copy_6[max_index_global_horizontal] = 255\n",
    "    show_images([original_image, image_copy_6], [\"Original Image\", \"Text Line Image\"])\n",
    "\n",
    "\n",
    "    local_minimas_horizontal = get_local_minimas_horizontal(horizontal_projection)\n",
    "\n",
    "    filtered_local_minimas = filter_local_minimas(local_minimas_horizontal)\n",
    "\n",
    "    word = fill_no_text_areas(word, filtered_local_minimas)\n",
    "\n",
    "    text_top_height, text_bottom_height = get_text_top_and_bottom(filtered_local_minimas, max_index_global_horizontal)\n",
    "\n",
    "    vertical_projection = get_vertical_projection(word)\n",
    "    #plot the vertical projection\n",
    "    plt.plot(vertical_projection)\n",
    "    plt.title(\"Vertical Projection\")\n",
    "    plt.show()\n",
    "\n",
    "    local_minimas  = find_local_minimas_in_vp(vertical_projection)\n",
    "\n",
    "    stable_areas = detect_stable_regions(vertical_projection)\n",
    "    \n",
    "    #plot the stable areas on the vertical projection\n",
    "    for start, end in stable_areas:\n",
    "        #color the stable areas in yellow\n",
    "        plt.axvline(start, color='y')\n",
    "        plt.axvline(end, color='y')\n",
    "        \n",
    "    plt.title(\"Vertical Projection with stable areas\")\n",
    "    plt.plot(vertical_projection)\n",
    "\n",
    "    average_values = get_average_values(vertical_projection, stable_areas)\n",
    "    #plot the average values of the stable areas on the vertical projection\n",
    "    for i, value in enumerate(average_values):\n",
    "        plt.axhline(value, color='g')\n",
    "    plt.title(\"Vertical Projection with stable areas and average values\")\n",
    "    plt.show()\n",
    "\n",
    "    merged_areas = merge_stable_areas(stable_areas, word.shape[1], average_values)\n",
    "    #draw the merged areas on the image\n",
    "    image_copy_2 = word.copy()\n",
    "    for start, end in merged_areas:\n",
    "        image_copy_2[:, start] = 255\n",
    "        image_copy_2[:, end] = 255\n",
    "    show_images([original_image, image_copy_2], [\"Original Image\", \"Merged Areas Image by stability\"])\n",
    "\n",
    "    height, width = word.shape\n",
    "\n",
    "    merged_areas = filter_small_areas(merged_areas, width)\n",
    "    #draw the filtered areas on the image\n",
    "    image_copy_1 = word.copy()\n",
    "    for start, end in merged_areas:\n",
    "        image_copy_1[:, start] = 255\n",
    "        image_copy_1[:, end] = 255\n",
    "    show_images([original_image, image_copy_1], [\"Original Image\", \"Filtered Areas Image by width\"])\n",
    "\n",
    "    average_values_merged = get_avg_value_of_merged_areas(merged_areas, vertical_projection)\n",
    "\n",
    "    filtered_areas = filter_too_high_vp(average_values_merged, merged_areas)\n",
    "    image_copy = word.copy()\n",
    "    for start, end in filtered_areas:\n",
    "        image_copy[:, start] = 255\n",
    "        image_copy[:, end] = 255\n",
    "    show_images([original_image, image_copy], [\"Original Image\", \"Filtered Areas Image by average value\"])\n",
    "\n",
    "    skeleton = skeletonize(word)\n",
    "    skeleton_image = np.where(skeleton, 255, 0).astype(np.uint8)\n",
    "    \n",
    "    filtered, empty_areas = filter_by_text_line(skeleton_image, filtered_areas, text_top_height, max_index_global_horizontal, text_bottom_height, word)\n",
    "    image_copy_3 = word.copy()\n",
    "    for start, end in filtered:\n",
    "        image_copy_3[:, start] = 255\n",
    "        image_copy_3[:, end] = 255\n",
    "    show_images([original_image, image_copy_3], [\"Original Image\", \"Filtered Areas Image by text line\"])\n",
    "\n",
    "    filtered_by_distance = filter_by_distances(filtered)\n",
    "    image_copy_4 = word.copy()\n",
    "    for start, end in filtered_by_distance:\n",
    "        image_copy_4[:, start] = 255\n",
    "        image_copy_4[:, end] = 255\n",
    "    show_images([original_image, image_copy_4], [\"Original Image\", \"Filtered Areas Image by distance\"])\n",
    "    split_points = get_split_points(filtered_by_distance, vertical_projection)\n",
    "\n",
    "    \n",
    "    if len(split_points) == 0:\n",
    "        return [original_image]\n",
    "    \n",
    "    image_copy_5 = word.copy()\n",
    "    \n",
    "    for point in split_points:\n",
    "        image_copy_5[:, point] = 255\n",
    "    show_images([original_image, image_copy_5], [\"Original Image\", \"Split Points Image\"])\n",
    "\n",
    "    words = []\n",
    "    words.append(original_image[:, :split_points[0]])\n",
    "    for i in range(len(split_points) - 1):\n",
    "        words.append(original_image[:, split_points[i]:split_points[i + 1]])\n",
    "    words.append(original_image[:, split_points[-1]:])\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_characters(words):\n",
    "    print('words:', len(words))\n",
    "    if len(words) == 1 or len(words) == 0:\n",
    "        return words\n",
    "    filtered_words = []\n",
    "    average_width = np.mean([word.shape[1] for word in words])\n",
    "    for word in words:\n",
    "        height, width = word.shape\n",
    "        if width < average_width * 0.5:\n",
    "            #check amount of white pixels in the word\n",
    "            white_pixels = np.sum(word == 255)\n",
    "            print('white pixels:', white_pixels)\n",
    "            print('total pixels:', height * width)\n",
    "            print('percentage:', white_pixels / (height * width))\n",
    "            if white_pixels / (height * width) <= 0.15:\n",
    "                continue\n",
    "        filtered_words.append(word)\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'D:/UNI/CCE_sem_8_LAST_YAY_^^/gp2/project/Alfarahifi_org/arabic-ocr/Trial/computer_par/line_0/word_1.png'\n",
    "\n",
    "# words = segment_characters(path)\n",
    "\n",
    "\n",
    "# filtered_words = filter_characters(words)\n",
    "\n",
    "# show_images(words)\n",
    "# show_images(filtered_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
