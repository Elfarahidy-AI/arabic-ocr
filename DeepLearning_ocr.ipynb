{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dmKqvJb8TTj"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvQEgsLcX-hV",
        "outputId": "10b31c48-1be8-4427-c0c4-dc74f4ae0b72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "z_QorwD780F6"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import joblib\n",
        "import pywt\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, SpatialDropout2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, LearningRateScheduler\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fm--It_m-u8f"
      },
      "outputs": [],
      "source": [
        "IMG_HEIGHT, IMG_WIDTH = 64, 64  # Example size, adjust as necessary\n",
        "\n",
        "data = []  # To store image data\n",
        "classes = []  # To store class labels\n",
        "directory = './drive/MyDrive/LettersDataset'\n",
        "chars = os.listdir(directory)  # Make sure this gets the right subdirectories\n",
        "for char in chars:\n",
        "    for position in ['Beginning', 'End', 'Isolated', 'Middle']:\n",
        "        path = os.path.join(directory, char, position)\n",
        "        if os.path.isdir(path):\n",
        "            listOfFiles = [os.path.join(path, f) for f in os.listdir(path) if f.endswith('.png')]  # Adjust extension if necessary\n",
        "            for filename in listOfFiles:\n",
        "                img = cv.imread(filename)\n",
        "                gray_img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "                cropped = cv.resize(gray_img, (IMG_HEIGHT, IMG_WIDTH))  # Resize to uniform size\n",
        "                binary_img = cv.threshold(cropped, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)[1]\n",
        "                binary_img = binary_img.reshape(IMG_HEIGHT, IMG_WIDTH, 1)  # Reshape to add channel dimension\n",
        "                data.append(binary_img.astype('float32') / 255.0)  # Normalize and add to data list\n",
        "                classes.append(char + position)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qMtsLhYNoEjV"
      },
      "outputs": [],
      "source": [
        "data = np.array(data)\n",
        "classes = np.array(classes)\n",
        "\n",
        "# Assuming `data` is your image array and `classes` is your array of labels\n",
        "'''indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "data = data[indices]\n",
        "classes = classes[indices]'''\n",
        "\n",
        "# Encode class labels\n",
        "encoder = LabelEncoder()\n",
        "encoded_classes = encoder.fit_transform(classes)\n",
        "categorical_labels = to_categorical(encoded_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LYOFjBTGq1RM"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data, categorical_labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEUV-bK2oKb_"
      },
      "outputs": [],
      "source": [
        "#model 1\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(categorical_labels[0]), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qYF5Tmcazpu",
        "outputId": "71ee120d-bde1-47d0-bbc0-10f70fea6f59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "194/194 [==============================] - 49s 255ms/step - loss: 0.5297 - accuracy: 0.7211 - val_loss: 1.3350 - val_accuracy: 0.4625\n",
            "Epoch 2/10\n",
            "194/194 [==============================] - 33s 172ms/step - loss: 0.5129 - accuracy: 0.7214 - val_loss: 1.3413 - val_accuracy: 0.4645\n",
            "Epoch 3/10\n",
            "194/194 [==============================] - 32s 167ms/step - loss: 0.5107 - accuracy: 0.7301 - val_loss: 1.4199 - val_accuracy: 0.4419\n",
            "Epoch 4/10\n",
            "194/194 [==============================] - 36s 187ms/step - loss: 0.5002 - accuracy: 0.7211 - val_loss: 1.5025 - val_accuracy: 0.4490\n",
            "Epoch 5/10\n",
            "194/194 [==============================] - 34s 177ms/step - loss: 0.5039 - accuracy: 0.7238 - val_loss: 1.4645 - val_accuracy: 0.4554\n",
            "Epoch 6/10\n",
            "194/194 [==============================] - 33s 173ms/step - loss: 0.4948 - accuracy: 0.7271 - val_loss: 1.3980 - val_accuracy: 0.4457\n",
            "Epoch 7/10\n",
            "194/194 [==============================] - 34s 175ms/step - loss: 0.4923 - accuracy: 0.7292 - val_loss: 1.4705 - val_accuracy: 0.4438\n",
            "Epoch 8/10\n",
            "194/194 [==============================] - 36s 184ms/step - loss: 0.4866 - accuracy: 0.7292 - val_loss: 1.4654 - val_accuracy: 0.4444\n",
            "Epoch 9/10\n",
            "194/194 [==============================] - 36s 186ms/step - loss: 0.4952 - accuracy: 0.7287 - val_loss: 1.5070 - val_accuracy: 0.4309\n",
            "Epoch 10/10\n",
            "194/194 [==============================] - 35s 181ms/step - loss: 0.4741 - accuracy: 0.7392 - val_loss: 1.5380 - val_accuracy: 0.4238\n",
            "61/61 [==============================] - 4s 65ms/step - loss: 1.6188 - accuracy: 0.4295\n",
            "Test accuracy: 42.95%\n"
          ]
        }
      ],
      "source": [
        "#model 1\n",
        "#10 epochs\n",
        "model.fit(X_train, y_train, epochs=10, validation_split=0.2)\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcesas6IoSew",
        "outputId": "8aa6e4d7-b71f-4d9c-e0a5-aef58fc1c9c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "194/194 [==============================] - 33s 172ms/step - loss: 0.7707 - accuracy: 0.6337 - val_loss: 1.0362 - val_accuracy: 0.5252\n",
            "Epoch 2/15\n",
            "194/194 [==============================] - 35s 183ms/step - loss: 0.7373 - accuracy: 0.6360 - val_loss: 1.0558 - val_accuracy: 0.5187\n",
            "Epoch 3/15\n",
            "194/194 [==============================] - 35s 179ms/step - loss: 0.7036 - accuracy: 0.6441 - val_loss: 1.0665 - val_accuracy: 0.4948\n",
            "Epoch 4/15\n",
            "194/194 [==============================] - 35s 179ms/step - loss: 0.6829 - accuracy: 0.6526 - val_loss: 1.0425 - val_accuracy: 0.5019\n",
            "Epoch 5/15\n",
            "194/194 [==============================] - 33s 169ms/step - loss: 0.6538 - accuracy: 0.6764 - val_loss: 1.0638 - val_accuracy: 0.5052\n",
            "Epoch 6/15\n",
            "194/194 [==============================] - 35s 179ms/step - loss: 0.6359 - accuracy: 0.6720 - val_loss: 1.1238 - val_accuracy: 0.4767\n",
            "Epoch 7/15\n",
            "194/194 [==============================] - 36s 185ms/step - loss: 0.6164 - accuracy: 0.6736 - val_loss: 1.1376 - val_accuracy: 0.5052\n",
            "Epoch 8/15\n",
            "194/194 [==============================] - 34s 174ms/step - loss: 0.5916 - accuracy: 0.6901 - val_loss: 1.1779 - val_accuracy: 0.4877\n",
            "Epoch 9/15\n",
            "194/194 [==============================] - 34s 174ms/step - loss: 0.5867 - accuracy: 0.6953 - val_loss: 1.1762 - val_accuracy: 0.4774\n",
            "Epoch 10/15\n",
            "194/194 [==============================] - 33s 172ms/step - loss: 0.5786 - accuracy: 0.6943 - val_loss: 1.2130 - val_accuracy: 0.4709\n",
            "Epoch 11/15\n",
            "194/194 [==============================] - 33s 172ms/step - loss: 0.5697 - accuracy: 0.7028 - val_loss: 1.2005 - val_accuracy: 0.4780\n",
            "Epoch 12/15\n",
            "194/194 [==============================] - 39s 202ms/step - loss: 0.5683 - accuracy: 0.6998 - val_loss: 1.2481 - val_accuracy: 0.4690\n",
            "Epoch 13/15\n",
            "194/194 [==============================] - 34s 174ms/step - loss: 0.5478 - accuracy: 0.7067 - val_loss: 1.3216 - val_accuracy: 0.4955\n",
            "Epoch 14/15\n",
            "194/194 [==============================] - 33s 172ms/step - loss: 0.5449 - accuracy: 0.7059 - val_loss: 1.3066 - val_accuracy: 0.4541\n",
            "Epoch 15/15\n",
            "194/194 [==============================] - 34s 175ms/step - loss: 0.5359 - accuracy: 0.7108 - val_loss: 1.2654 - val_accuracy: 0.4541\n",
            "61/61 [==============================] - 2s 39ms/step - loss: 1.3055 - accuracy: 0.4620\n",
            "Test accuracy: 46.20%\n"
          ]
        }
      ],
      "source": [
        "#model 1\n",
        "#15 epochs\n",
        "model.fit(X_train, y_train, epochs=15, validation_split=0.2)\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROaJ5HMvSx4u",
        "outputId": "fd826c9b-6f02-4b75-e9f9-f421b37eac25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "194/194 [==============================] - 42s 219ms/step - loss: 0.4755 - accuracy: 0.7424 - val_loss: 1.5752 - val_accuracy: 0.4186\n",
            "Epoch 2/10\n",
            "194/194 [==============================] - 38s 197ms/step - loss: 0.4597 - accuracy: 0.7492 - val_loss: 1.6154 - val_accuracy: 0.4309\n",
            "Epoch 3/10\n",
            "194/194 [==============================] - 33s 169ms/step - loss: 0.4726 - accuracy: 0.7413 - val_loss: 1.5974 - val_accuracy: 0.4406\n",
            "Epoch 4/10\n",
            "194/194 [==============================] - 37s 189ms/step - loss: 0.4672 - accuracy: 0.7382 - val_loss: 1.6399 - val_accuracy: 0.4231\n",
            "Epoch 5/10\n",
            "194/194 [==============================] - 33s 169ms/step - loss: 0.4582 - accuracy: 0.7511 - val_loss: 1.6913 - val_accuracy: 0.4348\n",
            "Epoch 6/10\n",
            "194/194 [==============================] - 33s 172ms/step - loss: 0.4612 - accuracy: 0.7424 - val_loss: 1.6885 - val_accuracy: 0.4154\n",
            "Epoch 7/10\n",
            "194/194 [==============================] - 33s 173ms/step - loss: 0.4572 - accuracy: 0.7476 - val_loss: 1.6366 - val_accuracy: 0.4257\n",
            "Epoch 8/10\n",
            "194/194 [==============================] - 34s 176ms/step - loss: 0.4546 - accuracy: 0.7461 - val_loss: 1.7520 - val_accuracy: 0.4289\n",
            "Epoch 9/10\n",
            "194/194 [==============================] - 36s 186ms/step - loss: 0.4518 - accuracy: 0.7445 - val_loss: 1.6605 - val_accuracy: 0.4193\n",
            "Epoch 10/10\n",
            "194/194 [==============================] - 33s 172ms/step - loss: 0.4487 - accuracy: 0.7490 - val_loss: 1.8112 - val_accuracy: 0.4044\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 1.8784 - accuracy: 0.4160\n",
            "Test accuracy: 41.60%\n"
          ]
        }
      ],
      "source": [
        "#model 1 with shuffling\n",
        "#10 epochs\n",
        "model.fit(X_train, y_train, epochs=10, validation_split=0.2)\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6hZIYV8zgky",
        "outputId": "5b62d19a-e307-424a-f963-dc09951b3486"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "194/194 [==============================] - 48s 245ms/step - loss: 0.4219 - accuracy: 0.7616 - val_loss: 2.0160 - val_accuracy: 0.3928\n",
            "Epoch 2/15\n",
            "194/194 [==============================] - 33s 167ms/step - loss: 0.4212 - accuracy: 0.7607 - val_loss: 1.9638 - val_accuracy: 0.3960\n",
            "Epoch 3/15\n",
            "194/194 [==============================] - 35s 178ms/step - loss: 0.4135 - accuracy: 0.7637 - val_loss: 1.9316 - val_accuracy: 0.4050\n",
            "Epoch 4/15\n",
            "194/194 [==============================] - 37s 191ms/step - loss: 0.4137 - accuracy: 0.7581 - val_loss: 1.9991 - val_accuracy: 0.4037\n",
            "Epoch 5/15\n",
            "194/194 [==============================] - 33s 171ms/step - loss: 0.4098 - accuracy: 0.7605 - val_loss: 2.0137 - val_accuracy: 0.3966\n",
            "Epoch 6/15\n",
            "194/194 [==============================] - 33s 170ms/step - loss: 0.4134 - accuracy: 0.7573 - val_loss: 2.0317 - val_accuracy: 0.4037\n",
            "Epoch 7/15\n",
            "194/194 [==============================] - 33s 171ms/step - loss: 0.4105 - accuracy: 0.7718 - val_loss: 1.9394 - val_accuracy: 0.4025\n",
            "Epoch 8/15\n",
            "194/194 [==============================] - 32s 167ms/step - loss: 0.4064 - accuracy: 0.7621 - val_loss: 1.9757 - val_accuracy: 0.3960\n",
            "Epoch 9/15\n",
            "194/194 [==============================] - 36s 184ms/step - loss: 0.4033 - accuracy: 0.7673 - val_loss: 2.1193 - val_accuracy: 0.4025\n",
            "Epoch 10/15\n",
            "194/194 [==============================] - 33s 172ms/step - loss: 0.3996 - accuracy: 0.7707 - val_loss: 2.2015 - val_accuracy: 0.3986\n",
            "Epoch 11/15\n",
            "194/194 [==============================] - 34s 173ms/step - loss: 0.3987 - accuracy: 0.7707 - val_loss: 2.1453 - val_accuracy: 0.3947\n",
            "Epoch 12/15\n",
            "194/194 [==============================] - 32s 167ms/step - loss: 0.3987 - accuracy: 0.7644 - val_loss: 2.1927 - val_accuracy: 0.3850\n",
            "Epoch 13/15\n",
            "194/194 [==============================] - 36s 185ms/step - loss: 0.4015 - accuracy: 0.7647 - val_loss: 2.1651 - val_accuracy: 0.3921\n",
            "Epoch 14/15\n",
            "194/194 [==============================] - 33s 171ms/step - loss: 0.4000 - accuracy: 0.7684 - val_loss: 2.2520 - val_accuracy: 0.4050\n",
            "Epoch 15/15\n",
            "194/194 [==============================] - 33s 171ms/step - loss: 0.3976 - accuracy: 0.7724 - val_loss: 2.2101 - val_accuracy: 0.3928\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 2.3081 - accuracy: 0.4114\n",
            "Test accuracy: 41.14%\n"
          ]
        }
      ],
      "source": [
        "#model 1 with shuffling\n",
        "#15 epochs\n",
        "model.fit(X_train, y_train, epochs=15, validation_split=0.2)\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "adQhlxwIHHh9"
      },
      "outputs": [],
      "source": [
        "#model 2 with shuffling\n",
        "# Initialize the data generator for augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,       # Degrees of random rotations\n",
        "    width_shift_range=0.1,   # Fraction of total width for horizontal shift\n",
        "    height_shift_range=0.1,  # Fraction of total height for vertical shift\n",
        "    shear_range=0.1,         # Shearing intensity\n",
        "    zoom_range=0.1,          # Range for random zoom\n",
        "    fill_mode='nearest'      # Strategy for filling in newly created pixels\n",
        ")\n",
        "\n",
        "# Fit the data generator on your training data\n",
        "datagen.fit(X_train)\n",
        "# Define the model architecture\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(categorical_labels[0]), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ri52Nl6lTOSG",
        "outputId": "eda07a6a-2e3c-4c35-e893-f4f8ed3a7c66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "242/242 [==============================] - 53s 212ms/step - loss: 3.0435 - accuracy: 0.0755 - val_loss: 2.6095 - val_accuracy: 0.1731 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "242/242 [==============================] - 51s 211ms/step - loss: 2.1544 - accuracy: 0.2888 - val_loss: 1.2193 - val_accuracy: 0.5307 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "242/242 [==============================] - 54s 221ms/step - loss: 1.5355 - accuracy: 0.4270 - val_loss: 1.0984 - val_accuracy: 0.5442 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "242/242 [==============================] - 51s 211ms/step - loss: 1.2854 - accuracy: 0.4901 - val_loss: 0.8770 - val_accuracy: 0.5809 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "242/242 [==============================] - 51s 210ms/step - loss: 1.1355 - accuracy: 0.5337 - val_loss: 0.8609 - val_accuracy: 0.5959 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "242/242 [==============================] - 51s 210ms/step - loss: 1.0787 - accuracy: 0.5342 - val_loss: 0.8557 - val_accuracy: 0.5979 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "242/242 [==============================] - 53s 218ms/step - loss: 1.0120 - accuracy: 0.5584 - val_loss: 0.7870 - val_accuracy: 0.6227 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "242/242 [==============================] - 51s 210ms/step - loss: 0.9775 - accuracy: 0.5642 - val_loss: 0.7681 - val_accuracy: 0.6036 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "242/242 [==============================] - 51s 212ms/step - loss: 0.9530 - accuracy: 0.5623 - val_loss: 0.7790 - val_accuracy: 0.6103 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "242/242 [==============================] - 55s 226ms/step - loss: 0.9265 - accuracy: 0.5798 - val_loss: 0.7519 - val_accuracy: 0.6202 - lr: 0.0010\n",
            "Epoch 11/15\n",
            "242/242 [==============================] - 52s 213ms/step - loss: 0.8999 - accuracy: 0.5779 - val_loss: 0.7307 - val_accuracy: 0.6305 - lr: 0.0010\n",
            "Epoch 12/15\n",
            "242/242 [==============================] - 51s 210ms/step - loss: 0.8692 - accuracy: 0.5901 - val_loss: 0.7566 - val_accuracy: 0.6176 - lr: 0.0010\n",
            "Epoch 13/15\n",
            "242/242 [==============================] - 53s 221ms/step - loss: 0.8605 - accuracy: 0.5840 - val_loss: 0.7659 - val_accuracy: 0.6124 - lr: 0.0010\n",
            "Epoch 14/15\n",
            "242/242 [==============================] - 50s 208ms/step - loss: 0.8335 - accuracy: 0.5994 - val_loss: 0.7176 - val_accuracy: 0.6315 - lr: 0.0010\n",
            "Epoch 15/15\n",
            "242/242 [==============================] - 50s 207ms/step - loss: 0.8281 - accuracy: 0.6103 - val_loss: 0.7837 - val_accuracy: 0.6160 - lr: 0.0010\n",
            "61/61 [==============================] - 3s 56ms/step - loss: 0.7837 - accuracy: 0.6160\n",
            "Test accuracy: 61.60%\n"
          ]
        }
      ],
      "source": [
        "#model 2 with shuffling\n",
        "# Train the model using the augmented data generator\n",
        "model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=32),\n",
        "    epochs=15,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[reduce_lr, early_stopping]\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bK1ksdwjU5O4",
        "outputId": "55098c71-6578-4ad5-cccb-b8b860a8c370"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "242/242 [==============================] - 59s 239ms/step - loss: 3.0003 - accuracy: 0.0890 - val_loss: 2.4675 - val_accuracy: 0.2377 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "242/242 [==============================] - 54s 222ms/step - loss: 2.1150 - accuracy: 0.2964 - val_loss: 1.3110 - val_accuracy: 0.4987 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "242/242 [==============================] - 56s 232ms/step - loss: 1.4935 - accuracy: 0.4364 - val_loss: 1.1843 - val_accuracy: 0.5085 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "242/242 [==============================] - 53s 221ms/step - loss: 1.2798 - accuracy: 0.4935 - val_loss: 0.9323 - val_accuracy: 0.5685 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "242/242 [==============================] - 56s 233ms/step - loss: 1.1570 - accuracy: 0.5161 - val_loss: 0.8679 - val_accuracy: 0.5850 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "242/242 [==============================] - 56s 232ms/step - loss: 1.0834 - accuracy: 0.5442 - val_loss: 0.9400 - val_accuracy: 0.5669 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "242/242 [==============================] - 57s 238ms/step - loss: 1.0130 - accuracy: 0.5615 - val_loss: 0.8662 - val_accuracy: 0.5907 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "242/242 [==============================] - 56s 232ms/step - loss: 0.9958 - accuracy: 0.5612 - val_loss: 0.8375 - val_accuracy: 0.5902 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "242/242 [==============================] - 55s 228ms/step - loss: 0.9548 - accuracy: 0.5718 - val_loss: 0.7842 - val_accuracy: 0.6021 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "242/242 [==============================] - 56s 230ms/step - loss: 0.9290 - accuracy: 0.5804 - val_loss: 0.8215 - val_accuracy: 0.5943 - lr: 0.0010\n",
            "Epoch 11/15\n",
            "242/242 [==============================] - 54s 223ms/step - loss: 0.9004 - accuracy: 0.5867 - val_loss: 0.7435 - val_accuracy: 0.6243 - lr: 0.0010\n",
            "Epoch 12/15\n",
            "242/242 [==============================] - 56s 230ms/step - loss: 0.8867 - accuracy: 0.5910 - val_loss: 0.8262 - val_accuracy: 0.6119 - lr: 0.0010\n",
            "Epoch 13/15\n",
            "242/242 [==============================] - 56s 233ms/step - loss: 0.8748 - accuracy: 0.5991 - val_loss: 0.7722 - val_accuracy: 0.5984 - lr: 0.0010\n",
            "Epoch 14/15\n",
            "242/242 [==============================] - 57s 237ms/step - loss: 0.8532 - accuracy: 0.6012 - val_loss: 0.7473 - val_accuracy: 0.6124 - lr: 0.0010\n",
            "Epoch 15/15\n",
            "242/242 [==============================] - 54s 221ms/step - loss: 0.8308 - accuracy: 0.6010 - val_loss: 0.7522 - val_accuracy: 0.6191 - lr: 0.0010\n",
            "61/61 [==============================] - 3s 57ms/step - loss: 0.7522 - accuracy: 0.6191\n",
            "Test accuracy: 61.91%\n"
          ]
        }
      ],
      "source": [
        "#model 2\n",
        "# Train the model using the augmented data generator\n",
        "model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=32),\n",
        "    epochs=15,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[reduce_lr, early_stopping]\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YndSzgyHwTxO",
        "outputId": "86e598ed-5b40-4c20-f139-3ed88bc9b037"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "242/242 [==============================] - 65s 262ms/step - loss: 2.9843 - accuracy: 0.0955 - val_loss: 2.2769 - val_accuracy: 0.2729 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "242/242 [==============================] - 58s 241ms/step - loss: 2.1154 - accuracy: 0.2986 - val_loss: 1.3322 - val_accuracy: 0.4956 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "242/242 [==============================] - 61s 254ms/step - loss: 1.5895 - accuracy: 0.4204 - val_loss: 1.0562 - val_accuracy: 0.5375 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "242/242 [==============================] - 57s 236ms/step - loss: 1.3305 - accuracy: 0.4836 - val_loss: 1.2911 - val_accuracy: 0.5028 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "242/242 [==============================] - 55s 228ms/step - loss: 1.2106 - accuracy: 0.5034 - val_loss: 0.8660 - val_accuracy: 0.5922 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "242/242 [==============================] - 59s 244ms/step - loss: 1.1166 - accuracy: 0.5395 - val_loss: 0.8572 - val_accuracy: 0.5974 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "242/242 [==============================] - 55s 228ms/step - loss: 1.0866 - accuracy: 0.5313 - val_loss: 0.8020 - val_accuracy: 0.6103 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "242/242 [==============================] - 58s 241ms/step - loss: 1.0352 - accuracy: 0.5481 - val_loss: 0.8007 - val_accuracy: 0.5969 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "242/242 [==============================] - 57s 235ms/step - loss: 1.0010 - accuracy: 0.5563 - val_loss: 0.8055 - val_accuracy: 0.5964 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "242/242 [==============================] - 61s 254ms/step - loss: 0.9658 - accuracy: 0.5668 - val_loss: 0.7543 - val_accuracy: 0.6207 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "242/242 [==============================] - 60s 248ms/step - loss: 0.9313 - accuracy: 0.5809 - val_loss: 0.7378 - val_accuracy: 0.6171 - lr: 9.0000e-04\n",
            "Epoch 12/50\n",
            "242/242 [==============================] - 58s 238ms/step - loss: 0.8988 - accuracy: 0.5841 - val_loss: 0.8126 - val_accuracy: 0.6000 - lr: 8.1000e-04\n",
            "Epoch 13/50\n",
            "242/242 [==============================] - 57s 236ms/step - loss: 0.8953 - accuracy: 0.5875 - val_loss: 0.7394 - val_accuracy: 0.6155 - lr: 7.2900e-04\n",
            "Epoch 14/50\n",
            "242/242 [==============================] - 59s 244ms/step - loss: 0.8599 - accuracy: 0.5928 - val_loss: 0.7257 - val_accuracy: 0.6119 - lr: 6.5610e-04\n",
            "Epoch 15/50\n",
            "242/242 [==============================] - 58s 239ms/step - loss: 0.8601 - accuracy: 0.5946 - val_loss: 0.7200 - val_accuracy: 0.6160 - lr: 5.9049e-04\n",
            "Epoch 16/50\n",
            "242/242 [==============================] - 57s 235ms/step - loss: 0.8372 - accuracy: 0.5994 - val_loss: 0.6994 - val_accuracy: 0.6248 - lr: 5.3144e-04\n",
            "Epoch 17/50\n",
            "242/242 [==============================] - 60s 247ms/step - loss: 0.8208 - accuracy: 0.6053 - val_loss: 0.7165 - val_accuracy: 0.6145 - lr: 4.7830e-04\n",
            "Epoch 18/50\n",
            "242/242 [==============================] - 59s 244ms/step - loss: 0.8090 - accuracy: 0.6156 - val_loss: 0.7178 - val_accuracy: 0.6196 - lr: 4.3047e-04\n",
            "Epoch 19/50\n",
            "242/242 [==============================] - 57s 235ms/step - loss: 0.7848 - accuracy: 0.6173 - val_loss: 0.7272 - val_accuracy: 0.6134 - lr: 3.8742e-04\n",
            "Epoch 20/50\n",
            "242/242 [==============================] - 59s 243ms/step - loss: 0.7978 - accuracy: 0.6147 - val_loss: 0.7075 - val_accuracy: 0.6212 - lr: 3.4868e-04\n",
            "Epoch 21/50\n",
            "242/242 [==============================] - 54s 225ms/step - loss: 0.7770 - accuracy: 0.6173 - val_loss: 0.6982 - val_accuracy: 0.6305 - lr: 3.1381e-04\n",
            "Epoch 22/50\n",
            "242/242 [==============================] - 58s 240ms/step - loss: 0.7859 - accuracy: 0.6116 - val_loss: 0.7026 - val_accuracy: 0.6222 - lr: 2.8243e-04\n",
            "Epoch 23/50\n",
            "242/242 [==============================] - 54s 224ms/step - loss: 0.7621 - accuracy: 0.6252 - val_loss: 0.7203 - val_accuracy: 0.6031 - lr: 2.5419e-04\n",
            "Epoch 24/50\n",
            "242/242 [==============================] - 59s 244ms/step - loss: 0.7579 - accuracy: 0.6220 - val_loss: 0.6912 - val_accuracy: 0.6155 - lr: 2.2877e-04\n",
            "Epoch 25/50\n",
            "242/242 [==============================] - 56s 229ms/step - loss: 0.7600 - accuracy: 0.6221 - val_loss: 0.6934 - val_accuracy: 0.6134 - lr: 2.0589e-04\n",
            "Epoch 26/50\n",
            "242/242 [==============================] - 60s 247ms/step - loss: 0.7533 - accuracy: 0.6244 - val_loss: 0.6835 - val_accuracy: 0.6202 - lr: 1.8530e-04\n",
            "Epoch 27/50\n",
            "242/242 [==============================] - 57s 236ms/step - loss: 0.7373 - accuracy: 0.6279 - val_loss: 0.6963 - val_accuracy: 0.6057 - lr: 1.6677e-04\n",
            "Epoch 28/50\n",
            "242/242 [==============================] - 55s 226ms/step - loss: 0.7352 - accuracy: 0.6270 - val_loss: 0.7012 - val_accuracy: 0.6078 - lr: 1.5009e-04\n",
            "Epoch 29/50\n",
            "242/242 [==============================] - 60s 249ms/step - loss: 0.7381 - accuracy: 0.6358 - val_loss: 0.6806 - val_accuracy: 0.5959 - lr: 1.3509e-04\n",
            "Epoch 30/50\n",
            "242/242 [==============================] - 55s 228ms/step - loss: 0.7360 - accuracy: 0.6344 - val_loss: 0.6957 - val_accuracy: 0.5964 - lr: 1.2158e-04\n",
            "Epoch 31/50\n",
            "242/242 [==============================] - 57s 235ms/step - loss: 0.7452 - accuracy: 0.6245 - val_loss: 0.6846 - val_accuracy: 0.5917 - lr: 1.0942e-04\n",
            "Epoch 32/50\n",
            "242/242 [==============================] - 56s 230ms/step - loss: 0.7311 - accuracy: 0.6295 - val_loss: 0.6801 - val_accuracy: 0.6021 - lr: 9.8477e-05\n",
            "Epoch 33/50\n",
            "242/242 [==============================] - 57s 235ms/step - loss: 0.7240 - accuracy: 0.6384 - val_loss: 0.6822 - val_accuracy: 0.6010 - lr: 8.8629e-05\n",
            "Epoch 34/50\n",
            "242/242 [==============================] - 56s 232ms/step - loss: 0.7302 - accuracy: 0.6323 - val_loss: 0.6902 - val_accuracy: 0.5964 - lr: 7.9766e-05\n",
            "Epoch 35/50\n",
            "242/242 [==============================] - 56s 229ms/step - loss: 0.7179 - accuracy: 0.6335 - val_loss: 0.6805 - val_accuracy: 0.5984 - lr: 7.1790e-05\n",
            "Epoch 36/50\n",
            "242/242 [==============================] - 58s 238ms/step - loss: 0.7112 - accuracy: 0.6420 - val_loss: 0.6785 - val_accuracy: 0.5969 - lr: 6.4611e-05\n",
            "Epoch 37/50\n",
            "242/242 [==============================] - 55s 228ms/step - loss: 0.7144 - accuracy: 0.6411 - val_loss: 0.6821 - val_accuracy: 0.6026 - lr: 5.8150e-05\n",
            "Epoch 38/50\n",
            "242/242 [==============================] - 58s 241ms/step - loss: 0.7191 - accuracy: 0.6328 - val_loss: 0.6809 - val_accuracy: 0.5979 - lr: 5.2335e-05\n",
            "Epoch 39/50\n",
            "242/242 [==============================] - 58s 240ms/step - loss: 0.7060 - accuracy: 0.6416 - val_loss: 0.6831 - val_accuracy: 0.5984 - lr: 4.7101e-05\n",
            "Epoch 40/50\n",
            "242/242 [==============================] - 59s 245ms/step - loss: 0.7061 - accuracy: 0.6339 - val_loss: 0.6841 - val_accuracy: 0.5984 - lr: 4.2391e-05\n",
            "Epoch 41/50\n",
            "242/242 [==============================] - 58s 240ms/step - loss: 0.7135 - accuracy: 0.6318 - val_loss: 0.6785 - val_accuracy: 0.5948 - lr: 3.8152e-05\n",
            "Epoch 42/50\n",
            "242/242 [==============================] - 55s 229ms/step - loss: 0.7141 - accuracy: 0.6403 - val_loss: 0.6875 - val_accuracy: 0.5917 - lr: 3.4337e-05\n",
            "Epoch 43/50\n",
            "242/242 [==============================] - 60s 248ms/step - loss: 0.7149 - accuracy: 0.6385 - val_loss: 0.6808 - val_accuracy: 0.5928 - lr: 3.0903e-05\n",
            "Epoch 44/50\n",
            "242/242 [==============================] - 55s 229ms/step - loss: 0.7056 - accuracy: 0.6357 - val_loss: 0.6812 - val_accuracy: 0.5938 - lr: 2.7813e-05\n",
            "Epoch 45/50\n",
            "242/242 [==============================] - 60s 247ms/step - loss: 0.6990 - accuracy: 0.6421 - val_loss: 0.6818 - val_accuracy: 0.5907 - lr: 2.5032e-05\n",
            "Epoch 46/50\n",
            "242/242 [==============================] - 58s 239ms/step - loss: 0.7040 - accuracy: 0.6428 - val_loss: 0.6777 - val_accuracy: 0.5959 - lr: 2.2528e-05\n",
            "Epoch 47/50\n",
            "242/242 [==============================] - 58s 239ms/step - loss: 0.7137 - accuracy: 0.6407 - val_loss: 0.6837 - val_accuracy: 0.5902 - lr: 2.0276e-05\n",
            "Epoch 48/50\n",
            "242/242 [==============================] - 58s 239ms/step - loss: 0.7110 - accuracy: 0.6408 - val_loss: 0.6813 - val_accuracy: 0.5907 - lr: 1.8248e-05\n",
            "Epoch 49/50\n",
            "242/242 [==============================] - 58s 239ms/step - loss: 0.7035 - accuracy: 0.6384 - val_loss: 0.6798 - val_accuracy: 0.5886 - lr: 1.6423e-05\n",
            "Epoch 50/50\n",
            "242/242 [==============================] - 59s 243ms/step - loss: 0.7105 - accuracy: 0.6460 - val_loss: 0.6848 - val_accuracy: 0.5938 - lr: 1.4781e-05\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e79092e2530>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#model 2 with learning rate changes\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 10:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * 0.9\n",
        "\n",
        "reduce_lr = LearningRateScheduler(scheduler)\n",
        "\n",
        "model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=32),\n",
        "    epochs=50,  # Increased epochs\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[reduce_lr, early_stopping]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ND0DbxJTuCh",
        "outputId": "dd8448df-79a9-4dd0-eb2f-5147fe6aaf9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "242/242 [==============================] - 58s 233ms/step - loss: 2.9664 - accuracy: 0.1012 - val_loss: 2.2705 - val_accuracy: 0.2904 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "242/242 [==============================] - 57s 234ms/step - loss: 2.0122 - accuracy: 0.3255 - val_loss: 1.2314 - val_accuracy: 0.5297 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "242/242 [==============================] - 54s 222ms/step - loss: 1.4413 - accuracy: 0.4522 - val_loss: 1.1051 - val_accuracy: 0.5349 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "242/242 [==============================] - 55s 227ms/step - loss: 1.2121 - accuracy: 0.5097 - val_loss: 0.8875 - val_accuracy: 0.5933 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "242/242 [==============================] - 54s 223ms/step - loss: 1.1008 - accuracy: 0.5371 - val_loss: 0.9479 - val_accuracy: 0.5726 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "242/242 [==============================] - 56s 232ms/step - loss: 1.0317 - accuracy: 0.5605 - val_loss: 0.8715 - val_accuracy: 0.5840 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "242/242 [==============================] - 56s 231ms/step - loss: 0.9797 - accuracy: 0.5707 - val_loss: 0.8415 - val_accuracy: 0.5969 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "242/242 [==============================] - 57s 234ms/step - loss: 0.9488 - accuracy: 0.5802 - val_loss: 0.7714 - val_accuracy: 0.6284 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "242/242 [==============================] - 54s 223ms/step - loss: 0.9141 - accuracy: 0.5939 - val_loss: 0.8524 - val_accuracy: 0.6083 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "242/242 [==============================] - 56s 231ms/step - loss: 0.8973 - accuracy: 0.5831 - val_loss: 0.7792 - val_accuracy: 0.6083 - lr: 0.0010\n",
            "Epoch 11/15\n",
            "242/242 [==============================] - 54s 222ms/step - loss: 0.8842 - accuracy: 0.5930 - val_loss: 0.7674 - val_accuracy: 0.6010 - lr: 9.0000e-04\n",
            "Epoch 12/15\n",
            "242/242 [==============================] - 54s 224ms/step - loss: 0.8440 - accuracy: 0.5999 - val_loss: 0.7539 - val_accuracy: 0.6196 - lr: 8.1000e-04\n",
            "Epoch 13/15\n",
            "242/242 [==============================] - 54s 225ms/step - loss: 0.8271 - accuracy: 0.6065 - val_loss: 0.7414 - val_accuracy: 0.6165 - lr: 7.2900e-04\n",
            "Epoch 14/15\n",
            "242/242 [==============================] - 54s 223ms/step - loss: 0.8109 - accuracy: 0.6109 - val_loss: 0.7109 - val_accuracy: 0.6207 - lr: 6.5610e-04\n",
            "Epoch 15/15\n",
            "242/242 [==============================] - 56s 232ms/step - loss: 0.7972 - accuracy: 0.6114 - val_loss: 0.7026 - val_accuracy: 0.6300 - lr: 5.9049e-04\n",
            "61/61 [==============================] - 3s 48ms/step - loss: 0.7026 - accuracy: 0.6300\n",
            "Test accuracy: 63.00%\n"
          ]
        }
      ],
      "source": [
        "def scheduler(epoch, lr):\n",
        "    if epoch < 10:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * 0.9\n",
        "\n",
        "reduce_lr = LearningRateScheduler(scheduler)\n",
        "\n",
        "model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=32),\n",
        "    epochs=15,  # Increased epochs\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[reduce_lr, early_stopping]\n",
        ")\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1AYD4-rU9e5",
        "outputId": "af10f4b6-9a68-418a-9400-cc36cbcc0ca3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model with 2 conv layers, 128 dense neurons, dropout 0.5, learning rate 0.001\n",
            "Epoch 1/15\n",
            "242/242 [==============================] - 62s 252ms/step - loss: 3.6477 - accuracy: 0.0528 - val_loss: 3.1263 - val_accuracy: 0.0687 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "242/242 [==============================] - 62s 254ms/step - loss: 3.2865 - accuracy: 0.0488 - val_loss: 5.0900 - val_accuracy: 0.0672 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "242/242 [==============================] - 61s 253ms/step - loss: 3.1670 - accuracy: 0.0519 - val_loss: 90.1802 - val_accuracy: 0.0537 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "242/242 [==============================] - 61s 253ms/step - loss: 3.1442 - accuracy: 0.0516 - val_loss: 8.3964 - val_accuracy: 0.0305 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "242/242 [==============================] - 62s 257ms/step - loss: 3.1286 - accuracy: 0.0513 - val_loss: 3.1253 - val_accuracy: 0.0543 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "242/242 [==============================] - 59s 243ms/step - loss: 3.1341 - accuracy: 0.0506 - val_loss: 3.1236 - val_accuracy: 0.0543 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "242/242 [==============================] - 62s 255ms/step - loss: 3.1255 - accuracy: 0.0513 - val_loss: 3.1259 - val_accuracy: 0.0543 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "242/242 [==============================] - 63s 260ms/step - loss: 3.1307 - accuracy: 0.0517 - val_loss: 23.1918 - val_accuracy: 0.0382 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "242/242 [==============================] - 65s 270ms/step - loss: 3.1212 - accuracy: 0.0513 - val_loss: 3.1199 - val_accuracy: 0.0543 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "242/242 [==============================] - 60s 249ms/step - loss: 3.1214 - accuracy: 0.0510 - val_loss: 3.8107 - val_accuracy: 0.0470 - lr: 0.0010\n",
            "Epoch 11/15\n",
            "242/242 [==============================] - 65s 268ms/step - loss: 3.1209 - accuracy: 0.0516 - val_loss: 3.1251 - val_accuracy: 0.0543 - lr: 0.0010\n",
            "Epoch 12/15\n",
            "242/242 [==============================] - 64s 266ms/step - loss: 3.1239 - accuracy: 0.0513 - val_loss: 83.0879 - val_accuracy: 0.0496 - lr: 0.0010\n",
            "Epoch 13/15\n",
            "242/242 [==============================] - 64s 265ms/step - loss: 3.1260 - accuracy: 0.0516 - val_loss: 7.0021 - val_accuracy: 0.0424 - lr: 0.0010\n",
            "Epoch 14/15\n",
            "242/242 [==============================] - 62s 256ms/step - loss: 3.1202 - accuracy: 0.0514 - val_loss: 3.1212 - val_accuracy: 0.0543 - lr: 0.0010\n",
            "Epoch 15/15\n",
            "242/242 [==============================] - 65s 271ms/step - loss: 3.1216 - accuracy: 0.0512 - val_loss: 4.2590 - val_accuracy: 0.0388 - lr: 2.0000e-04\n",
            "61/61 [==============================] - 3s 46ms/step - loss: 4.2590 - accuracy: 0.0388\n",
            "Test accuracy: 3.88%\n",
            "\n",
            "Training model with 2 conv layers, 128 dense neurons, dropout 0.5, learning rate 0.0005\n",
            "Epoch 1/15\n",
            "242/242 [==============================] - 115s 246ms/step - loss: 3.4702 - accuracy: 0.0528 - val_loss: 3.1292 - val_accuracy: 0.0553 - lr: 5.0000e-04\n",
            "Epoch 2/15\n",
            "242/242 [==============================] - 60s 248ms/step - loss: 3.2173 - accuracy: 0.0518 - val_loss: 3.1132 - val_accuracy: 0.0811 - lr: 5.0000e-04\n",
            "Epoch 3/15\n",
            "242/242 [==============================] - 58s 242ms/step - loss: 3.1591 - accuracy: 0.0660 - val_loss: 2.9692 - val_accuracy: 0.0977 - lr: 5.0000e-04\n",
            "Epoch 4/15\n",
            "242/242 [==============================] - 59s 245ms/step - loss: 3.0468 - accuracy: 0.0800 - val_loss: 2.7938 - val_accuracy: 0.1349 - lr: 5.0000e-04\n",
            "Epoch 5/15\n",
            "242/242 [==============================] - 61s 253ms/step - loss: 2.9624 - accuracy: 0.0978 - val_loss: 3.0710 - val_accuracy: 0.0920 - lr: 5.0000e-04\n",
            "Epoch 6/15\n",
            "242/242 [==============================] - 59s 244ms/step - loss: 2.9015 - accuracy: 0.1087 - val_loss: 2.7471 - val_accuracy: 0.1525 - lr: 5.0000e-04\n",
            "Epoch 7/15\n",
            "242/242 [==============================] - 62s 256ms/step - loss: 2.8566 - accuracy: 0.1182 - val_loss: 2.5490 - val_accuracy: 0.1860 - lr: 5.0000e-04\n",
            "Epoch 8/15\n",
            "242/242 [==============================] - 62s 256ms/step - loss: 2.7864 - accuracy: 0.1295 - val_loss: 3.1123 - val_accuracy: 0.1199 - lr: 5.0000e-04\n",
            "Epoch 9/15\n",
            "242/242 [==============================] - 59s 244ms/step - loss: 2.7420 - accuracy: 0.1410 - val_loss: 3.6010 - val_accuracy: 0.0599 - lr: 5.0000e-04\n",
            "Epoch 10/15\n",
            "242/242 [==============================] - 60s 246ms/step - loss: 2.6790 - accuracy: 0.1459 - val_loss: 2.8000 - val_accuracy: 0.1240 - lr: 5.0000e-04\n",
            "Epoch 11/15\n",
            "242/242 [==============================] - 60s 246ms/step - loss: 2.6052 - accuracy: 0.1588 - val_loss: 2.3048 - val_accuracy: 0.2382 - lr: 5.0000e-04\n",
            "Epoch 12/15\n",
            "242/242 [==============================] - 60s 247ms/step - loss: 2.5681 - accuracy: 0.1673 - val_loss: 3.1601 - val_accuracy: 0.1561 - lr: 5.0000e-04\n",
            "Epoch 13/15\n",
            "242/242 [==============================] - 57s 236ms/step - loss: 2.4931 - accuracy: 0.1792 - val_loss: 2.9357 - val_accuracy: 0.1406 - lr: 5.0000e-04\n",
            "Epoch 14/15\n",
            "242/242 [==============================] - 59s 243ms/step - loss: 2.4394 - accuracy: 0.1801 - val_loss: 2.9515 - val_accuracy: 0.1519 - lr: 5.0000e-04\n",
            "Epoch 15/15\n",
            "242/242 [==============================] - 60s 246ms/step - loss: 2.3849 - accuracy: 0.2018 - val_loss: 3.0670 - val_accuracy: 0.1783 - lr: 5.0000e-04\n",
            "61/61 [==============================] - 3s 46ms/step - loss: 3.0670 - accuracy: 0.1783\n",
            "Test accuracy: 17.83%\n",
            "\n",
            "Training model with 2 conv layers, 128 dense neurons, dropout 0.6, learning rate 0.001\n",
            "Epoch 1/15\n",
            "242/242 [==============================] - 61s 248ms/step - loss: 3.7965 - accuracy: 0.0451 - val_loss: 3.1301 - val_accuracy: 0.0326 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "242/242 [==============================] - 57s 236ms/step - loss: 3.2266 - accuracy: 0.0492 - val_loss: 3.1281 - val_accuracy: 0.0605 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "242/242 [==============================] - 61s 252ms/step - loss: 3.1945 - accuracy: 0.0513 - val_loss: 3.1260 - val_accuracy: 0.0543 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "242/242 [==============================] - 62s 255ms/step - loss: 3.1351 - accuracy: 0.0512 - val_loss: 3.1431 - val_accuracy: 0.0548 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "242/242 [==============================] - 59s 245ms/step - loss: 3.1434 - accuracy: 0.0517 - val_loss: 3.1253 - val_accuracy: 0.0548 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "242/242 [==============================] - 59s 245ms/step - loss: 3.1422 - accuracy: 0.0518 - val_loss: 3.1229 - val_accuracy: 0.0543 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "242/242 [==============================] - 59s 246ms/step - loss: 3.1258 - accuracy: 0.0509 - val_loss: 3.1226 - val_accuracy: 0.0543 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "242/242 [==============================] - 59s 244ms/step - loss: 3.1246 - accuracy: 0.0513 - val_loss: 3.1286 - val_accuracy: 0.0558 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "242/242 [==============================] - 61s 250ms/step - loss: 3.1217 - accuracy: 0.0512 - val_loss: 3.1240 - val_accuracy: 0.0543 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "242/242 [==============================] - 59s 244ms/step - loss: 3.1304 - accuracy: 0.0512 - val_loss: 3.1220 - val_accuracy: 0.0543 - lr: 0.0010\n",
            "Epoch 11/15\n",
            "242/242 [==============================] - 58s 239ms/step - loss: 3.1215 - accuracy: 0.0512 - val_loss: 3.1230 - val_accuracy: 0.0543 - lr: 0.0010\n",
            "Epoch 12/15\n",
            "242/242 [==============================] - 59s 245ms/step - loss: 3.1253 - accuracy: 0.0510 - val_loss: 3.1214 - val_accuracy: 0.0543 - lr: 0.0010\n",
            "Epoch 13/15\n",
            "242/242 [==============================] - 62s 254ms/step - loss: 3.1214 - accuracy: 0.0513 - val_loss: 3.1211 - val_accuracy: 0.0543 - lr: 0.0010\n",
            "Epoch 14/15\n",
            "242/242 [==============================] - 59s 242ms/step - loss: 3.1221 - accuracy: 0.0509 - val_loss: 3.1207 - val_accuracy: 0.0543 - lr: 0.0010\n",
            "Epoch 15/15\n",
            "242/242 [==============================] - 59s 243ms/step - loss: 3.1210 - accuracy: 0.0512 - val_loss: 3.1206 - val_accuracy: 0.0543 - lr: 0.0010\n",
            "61/61 [==============================] - 3s 46ms/step - loss: 3.1206 - accuracy: 0.0543\n",
            "Test accuracy: 5.43%\n",
            "\n",
            "Training model with 2 conv layers, 128 dense neurons, dropout 0.6, learning rate 0.0005\n",
            "Epoch 1/15\n",
            "242/242 [==============================] - 62s 246ms/step - loss: 3.4644 - accuracy: 0.0469 - val_loss: 3.1260 - val_accuracy: 0.0424 - lr: 5.0000e-04\n",
            "Epoch 2/15\n",
            "242/242 [==============================] - 60s 246ms/step - loss: 3.2915 - accuracy: 0.0506 - val_loss: 3.1362 - val_accuracy: 0.0558 - lr: 5.0000e-04\n",
            "Epoch 3/15\n",
            "242/242 [==============================] - 60s 248ms/step - loss: 3.2007 - accuracy: 0.0537 - val_loss: 3.1392 - val_accuracy: 0.0558 - lr: 5.0000e-04\n",
            "Epoch 4/15\n",
            "242/242 [==============================] - 62s 255ms/step - loss: 3.1643 - accuracy: 0.0506 - val_loss: 3.1331 - val_accuracy: 0.0553 - lr: 5.0000e-04\n",
            "Epoch 5/15\n",
            "242/242 [==============================] - 62s 254ms/step - loss: 3.1551 - accuracy: 0.0521 - val_loss: 3.1386 - val_accuracy: 0.0563 - lr: 5.0000e-04\n",
            "Epoch 6/15\n",
            "242/242 [==============================] - 59s 244ms/step - loss: 3.1460 - accuracy: 0.0514 - val_loss: 3.1275 - val_accuracy: 0.0548 - lr: 5.0000e-04\n",
            "Epoch 7/15\n",
            "242/242 [==============================] - 60s 247ms/step - loss: 3.1375 - accuracy: 0.0512 - val_loss: 3.1271 - val_accuracy: 0.0553 - lr: 1.0000e-04\n",
            "Epoch 8/15\n",
            "242/242 [==============================] - 60s 247ms/step - loss: 3.1284 - accuracy: 0.0522 - val_loss: 3.1261 - val_accuracy: 0.0553 - lr: 1.0000e-04\n",
            "Epoch 9/15\n",
            "242/242 [==============================] - 58s 241ms/step - loss: 3.1403 - accuracy: 0.0516 - val_loss: 3.1215 - val_accuracy: 0.0574 - lr: 1.0000e-04\n",
            "Epoch 10/15\n",
            "242/242 [==============================] - 63s 261ms/step - loss: 3.1348 - accuracy: 0.0521 - val_loss: 3.1258 - val_accuracy: 0.0543 - lr: 1.0000e-04\n",
            "Epoch 11/15\n",
            "242/242 [==============================] - 60s 248ms/step - loss: 3.1284 - accuracy: 0.0518 - val_loss: 3.1193 - val_accuracy: 0.0594 - lr: 1.0000e-04\n",
            "Epoch 12/15\n",
            "242/242 [==============================] - 60s 247ms/step - loss: 3.1299 - accuracy: 0.0523 - val_loss: 3.1041 - val_accuracy: 0.0651 - lr: 1.0000e-04\n",
            "Epoch 13/15\n",
            "242/242 [==============================] - 60s 248ms/step - loss: 3.1239 - accuracy: 0.0563 - val_loss: 3.0718 - val_accuracy: 0.0729 - lr: 1.0000e-04\n",
            "Epoch 14/15\n",
            "242/242 [==============================] - 58s 240ms/step - loss: 3.1177 - accuracy: 0.0553 - val_loss: 3.0540 - val_accuracy: 0.0693 - lr: 1.0000e-04\n",
            "Epoch 15/15\n",
            "242/242 [==============================] - 62s 257ms/step - loss: 3.1011 - accuracy: 0.0575 - val_loss: 3.0156 - val_accuracy: 0.0703 - lr: 1.0000e-04\n",
            "61/61 [==============================] - 5s 77ms/step - loss: 3.0156 - accuracy: 0.0703\n",
            "Test accuracy: 7.03%\n",
            "\n",
            "Training model with 2 conv layers, 256 dense neurons, dropout 0.5, learning rate 0.001\n",
            "Epoch 1/15\n",
            "242/242 [==============================] - 68s 276ms/step - loss: 3.8520 - accuracy: 0.0606 - val_loss: 3.3355 - val_accuracy: 0.0537 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "242/242 [==============================] - 70s 288ms/step - loss: 3.1181 - accuracy: 0.0773 - val_loss: 3.7529 - val_accuracy: 0.0439 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "242/242 [==============================] - 67s 278ms/step - loss: 2.9139 - accuracy: 0.0942 - val_loss: 2.8272 - val_accuracy: 0.1245 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "242/242 [==============================] - 67s 275ms/step - loss: 2.8299 - accuracy: 0.1048 - val_loss: 10.1255 - val_accuracy: 0.0439 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "242/242 [==============================] - 70s 287ms/step - loss: 2.7652 - accuracy: 0.1118 - val_loss: 3.1440 - val_accuracy: 0.1070 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "242/242 [==============================] - 65s 268ms/step - loss: 2.6929 - accuracy: 0.1328 - val_loss: 2.7712 - val_accuracy: 0.1318 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "242/242 [==============================] - 66s 271ms/step - loss: 2.6212 - accuracy: 0.1488 - val_loss: 11.0937 - val_accuracy: 0.0827 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "242/242 [==============================] - 67s 277ms/step - loss: 2.5420 - accuracy: 0.1633 - val_loss: 9.4195 - val_accuracy: 0.0972 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "242/242 [==============================] - 65s 269ms/step - loss: 2.4976 - accuracy: 0.1761 - val_loss: 11.7393 - val_accuracy: 0.0873 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "242/242 [==============================] - 67s 278ms/step - loss: 2.5053 - accuracy: 0.1798 - val_loss: 76.5702 - val_accuracy: 0.0408 - lr: 0.0010\n",
            "Epoch 11/15\n",
            "242/242 [==============================] - 66s 272ms/step - loss: 2.4093 - accuracy: 0.1968 - val_loss: 13.2573 - val_accuracy: 0.0894 - lr: 0.0010\n",
            "Epoch 12/15\n",
            "242/242 [==============================] - 65s 269ms/step - loss: 2.2947 - accuracy: 0.2214 - val_loss: 3.6377 - val_accuracy: 0.1576 - lr: 2.0000e-04\n",
            "Epoch 13/15\n",
            "242/242 [==============================] - 66s 271ms/step - loss: 2.2384 - accuracy: 0.2357 - val_loss: 2.1229 - val_accuracy: 0.2832 - lr: 2.0000e-04\n",
            "Epoch 14/15\n",
            "242/242 [==============================] - 67s 278ms/step - loss: 2.2099 - accuracy: 0.2348 - val_loss: 2.2848 - val_accuracy: 0.2904 - lr: 2.0000e-04\n",
            "Epoch 15/15\n",
            "242/242 [==============================] - 65s 269ms/step - loss: 2.1718 - accuracy: 0.2528 - val_loss: 1.6591 - val_accuracy: 0.4072 - lr: 2.0000e-04\n",
            "61/61 [==============================] - 3s 53ms/step - loss: 1.6591 - accuracy: 0.4072\n",
            "Test accuracy: 40.72%\n",
            "\n",
            "Training model with 2 conv layers, 256 dense neurons, dropout 0.5, learning rate 0.0005\n",
            "Epoch 1/15\n",
            "242/242 [==============================] - 72s 292ms/step - loss: 3.6196 - accuracy: 0.0720 - val_loss: 3.3820 - val_accuracy: 0.0465 - lr: 5.0000e-04\n",
            "Epoch 2/15\n",
            "242/242 [==============================] - 71s 291ms/step - loss: 3.1299 - accuracy: 0.1036 - val_loss: 2.7664 - val_accuracy: 0.1897 - lr: 5.0000e-04\n",
            "Epoch 3/15\n",
            "242/242 [==============================] - 69s 286ms/step - loss: 2.8641 - accuracy: 0.1393 - val_loss: 2.7770 - val_accuracy: 0.1406 - lr: 5.0000e-04\n",
            "Epoch 4/15\n",
            "242/242 [==============================] - 65s 269ms/step - loss: 2.6525 - accuracy: 0.1711 - val_loss: 3.4842 - val_accuracy: 0.1473 - lr: 5.0000e-04\n",
            "Epoch 5/15\n",
            "242/242 [==============================] - 65s 267ms/step - loss: 2.4470 - accuracy: 0.2008 - val_loss: 2.1396 - val_accuracy: 0.2879 - lr: 5.0000e-04\n",
            "Epoch 6/15\n",
            "242/242 [==============================] - 70s 288ms/step - loss: 2.2783 - accuracy: 0.2327 - val_loss: 3.9007 - val_accuracy: 0.1700 - lr: 5.0000e-04\n",
            "Epoch 7/15\n",
            "242/242 [==============================] - 68s 280ms/step - loss: 2.1464 - accuracy: 0.2722 - val_loss: 25.2137 - val_accuracy: 0.0873 - lr: 5.0000e-04\n",
            "Epoch 8/15\n",
            "242/242 [==============================] - 68s 279ms/step - loss: 2.0266 - accuracy: 0.2904 - val_loss: 3.1892 - val_accuracy: 0.2450 - lr: 5.0000e-04\n",
            "Epoch 9/15\n",
            "242/242 [==============================] - 65s 267ms/step - loss: 1.9156 - accuracy: 0.3204 - val_loss: 1.8807 - val_accuracy: 0.3747 - lr: 5.0000e-04\n",
            "Epoch 10/15\n",
            "242/242 [==============================] - 64s 266ms/step - loss: 1.8344 - accuracy: 0.3453 - val_loss: 4.0076 - val_accuracy: 0.2382 - lr: 5.0000e-04\n",
            "Epoch 11/15\n",
            "242/242 [==============================] - 69s 287ms/step - loss: 1.7693 - accuracy: 0.3592 - val_loss: 1.6974 - val_accuracy: 0.4052 - lr: 5.0000e-04\n",
            "Epoch 12/15\n",
            "242/242 [==============================] - 68s 282ms/step - loss: 1.7462 - accuracy: 0.3583 - val_loss: 61.0414 - val_accuracy: 0.0481 - lr: 5.0000e-04\n",
            "Epoch 13/15\n",
            "242/242 [==============================] - 64s 266ms/step - loss: 1.6885 - accuracy: 0.3712 - val_loss: 2.1497 - val_accuracy: 0.3571 - lr: 5.0000e-04\n",
            "Epoch 14/15\n",
            "242/242 [==============================] - 67s 277ms/step - loss: 1.6543 - accuracy: 0.3841 - val_loss: 4.6318 - val_accuracy: 0.2755 - lr: 5.0000e-04\n",
            "Epoch 15/15\n",
            "242/242 [==============================] - 68s 279ms/step - loss: 1.6243 - accuracy: 0.3994 - val_loss: 5.2205 - val_accuracy: 0.2098 - lr: 5.0000e-04\n",
            "61/61 [==============================] - 3s 51ms/step - loss: 5.2205 - accuracy: 0.2098\n",
            "Test accuracy: 20.98%\n",
            "\n",
            "Training model with 2 conv layers, 256 dense neurons, dropout 0.6, learning rate 0.001\n",
            "Epoch 1/15\n",
            "242/242 [==============================] - 71s 287ms/step - loss: 4.2204 - accuracy: 0.0519 - val_loss: 3.1307 - val_accuracy: 0.0357 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "242/242 [==============================] - 66s 273ms/step - loss: 3.3532 - accuracy: 0.0497 - val_loss: 3.1388 - val_accuracy: 0.0382 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "242/242 [==============================] - 66s 272ms/step - loss: 3.2074 - accuracy: 0.0461 - val_loss: 46.9393 - val_accuracy: 0.0388 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "242/242 [==============================] - 64s 264ms/step - loss: 3.1532 - accuracy: 0.0506 - val_loss: 3.1343 - val_accuracy: 0.0532 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "242/242 [==============================] - 67s 277ms/step - loss: 3.1444 - accuracy: 0.0519 - val_loss: 3.1232 - val_accuracy: 0.0558 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "242/242 [==============================] - 69s 285ms/step - loss: 3.1407 - accuracy: 0.0516 - val_loss: 3.9178 - val_accuracy: 0.0553 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "242/242 [==============================] - 67s 278ms/step - loss: 3.1316 - accuracy: 0.0512 - val_loss: 3.4425 - val_accuracy: 0.0620 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "242/242 [==============================] - 67s 277ms/step - loss: 3.1213 - accuracy: 0.0513 - val_loss: 94.5884 - val_accuracy: 0.0320 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "242/242 [==============================] - 68s 280ms/step - loss: 3.1241 - accuracy: 0.0517 - val_loss: 3.1142 - val_accuracy: 0.0563 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "242/242 [==============================] - 66s 274ms/step - loss: 3.1246 - accuracy: 0.0513 - val_loss: 44.6621 - val_accuracy: 0.0357 - lr: 0.0010\n",
            "Epoch 11/15\n",
            "242/242 [==============================] - 64s 265ms/step - loss: 3.1129 - accuracy: 0.0518 - val_loss: 3.6111 - val_accuracy: 0.0517 - lr: 0.0010\n",
            "Epoch 12/15\n",
            "242/242 [==============================] - 64s 266ms/step - loss: 3.1073 - accuracy: 0.0506 - val_loss: 618.8657 - val_accuracy: 0.0429 - lr: 0.0010\n",
            "Epoch 13/15\n",
            "242/242 [==============================] - 65s 267ms/step - loss: 3.0985 - accuracy: 0.0534 - val_loss: 484.5649 - val_accuracy: 0.0429 - lr: 0.0010\n",
            "Epoch 14/15\n",
            "242/242 [==============================] - 64s 264ms/step - loss: 3.0761 - accuracy: 0.0625 - val_loss: 18.9368 - val_accuracy: 0.0465 - lr: 0.0010\n",
            "Epoch 15/15\n",
            "242/242 [==============================] - 67s 276ms/step - loss: 3.0538 - accuracy: 0.0640 - val_loss: 2.9203 - val_accuracy: 0.0842 - lr: 2.0000e-04\n",
            "61/61 [==============================] - 4s 61ms/step - loss: 2.9203 - accuracy: 0.0842\n",
            "Test accuracy: 8.42%\n",
            "\n",
            "Training model with 2 conv layers, 256 dense neurons, dropout 0.6, learning rate 0.0005\n",
            "Epoch 1/15\n",
            "242/242 [==============================] - 66s 268ms/step - loss: 3.7698 - accuracy: 0.0661 - val_loss: 3.2283 - val_accuracy: 0.0460 - lr: 5.0000e-04\n",
            "Epoch 2/15\n",
            "242/242 [==============================] - 68s 280ms/step - loss: 3.3232 - accuracy: 0.0636 - val_loss: 3.0120 - val_accuracy: 0.0961 - lr: 5.0000e-04\n",
            "Epoch 3/15\n",
            "242/242 [==============================] - 65s 267ms/step - loss: 3.1054 - accuracy: 0.0725 - val_loss: 3.1356 - val_accuracy: 0.0687 - lr: 5.0000e-04\n",
            "Epoch 4/15\n",
            "242/242 [==============================] - 67s 277ms/step - loss: 3.0824 - accuracy: 0.0724 - val_loss: 3.2888 - val_accuracy: 0.0894 - lr: 5.0000e-04\n",
            "Epoch 5/15\n",
            "242/242 [==============================] - 66s 271ms/step - loss: 3.0236 - accuracy: 0.0880 - val_loss: 4.5360 - val_accuracy: 0.0579 - lr: 5.0000e-04\n",
            "Epoch 6/15\n",
            "242/242 [==============================] - 64s 265ms/step - loss: 2.9578 - accuracy: 0.0932 - val_loss: 2.7695 - val_accuracy: 0.1364 - lr: 5.0000e-04\n",
            "Epoch 7/15\n",
            "242/242 [==============================] - 67s 277ms/step - loss: 2.8999 - accuracy: 0.1036 - val_loss: 13.5374 - val_accuracy: 0.0610 - lr: 5.0000e-04\n",
            "Epoch 8/15\n",
            "242/242 [==============================] - 67s 277ms/step - loss: 2.8144 - accuracy: 0.1161 - val_loss: 2.4442 - val_accuracy: 0.2062 - lr: 5.0000e-04\n",
            "Epoch 9/15\n",
            "242/242 [==============================] - 67s 278ms/step - loss: 2.6953 - accuracy: 0.1300 - val_loss: 2.5790 - val_accuracy: 0.1762 - lr: 5.0000e-04\n",
            "Epoch 10/15\n",
            "242/242 [==============================] - 66s 274ms/step - loss: 2.5905 - accuracy: 0.1557 - val_loss: 9.7298 - val_accuracy: 0.1276 - lr: 5.0000e-04\n",
            "Epoch 11/15\n",
            "242/242 [==============================] - 64s 266ms/step - loss: 2.5258 - accuracy: 0.1709 - val_loss: 2.5725 - val_accuracy: 0.1788 - lr: 5.0000e-04\n",
            "Epoch 12/15\n",
            "242/242 [==============================] - 67s 275ms/step - loss: 2.4322 - accuracy: 0.1844 - val_loss: 2.3561 - val_accuracy: 0.1928 - lr: 5.0000e-04\n",
            "Epoch 13/15\n",
            "242/242 [==============================] - 67s 278ms/step - loss: 2.3900 - accuracy: 0.1917 - val_loss: 16.1998 - val_accuracy: 0.1432 - lr: 5.0000e-04\n",
            "Epoch 14/15\n",
            "242/242 [==============================] - 66s 274ms/step - loss: 2.3293 - accuracy: 0.2048 - val_loss: 2.1396 - val_accuracy: 0.2553 - lr: 5.0000e-04\n",
            "Epoch 15/15\n",
            "242/242 [==============================] - 64s 265ms/step - loss: 2.2544 - accuracy: 0.2306 - val_loss: 87.9755 - val_accuracy: 0.0470 - lr: 5.0000e-04\n",
            "61/61 [==============================] - 3s 51ms/step - loss: 87.9755 - accuracy: 0.0470\n",
            "Test accuracy: 4.70%\n",
            "\n",
            "Training model with 3 conv layers, 128 dense neurons, dropout 0.5, learning rate 0.001\n",
            "Epoch 1/15\n",
            "242/242 [==============================] - 67s 268ms/step - loss: 3.1553 - accuracy: 0.0784 - val_loss: 4.7406 - val_accuracy: 0.0377 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "242/242 [==============================] - 64s 263ms/step - loss: 2.7475 - accuracy: 0.1437 - val_loss: 2.4113 - val_accuracy: 0.2357 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "242/242 [==============================] - 66s 273ms/step - loss: 2.3272 - accuracy: 0.2138 - val_loss: 4.7780 - val_accuracy: 0.1178 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "242/242 [==============================] - 64s 266ms/step - loss: 1.9978 - accuracy: 0.2886 - val_loss: 4.3122 - val_accuracy: 0.1132 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "242/242 [==============================] - 65s 269ms/step - loss: 1.8035 - accuracy: 0.3326 - val_loss: 3.7233 - val_accuracy: 0.1860 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "242/242 [==============================] - 66s 273ms/step - loss: 1.6354 - accuracy: 0.3845 - val_loss: 1.5363 - val_accuracy: 0.4682 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "242/242 [==============================] - 63s 262ms/step - loss: 1.5020 - accuracy: 0.4142 - val_loss: 1.2845 - val_accuracy: 0.4977 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "242/242 [==============================] - 66s 273ms/step - loss: 1.4482 - accuracy: 0.4300 - val_loss: 2.2606 - val_accuracy: 0.3287 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "242/242 [==============================] - 63s 262ms/step - loss: 1.3655 - accuracy: 0.4636 - val_loss: 5.0054 - val_accuracy: 0.1829 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "242/242 [==============================] - 66s 271ms/step - loss: 1.2841 - accuracy: 0.4859 - val_loss: 3.1862 - val_accuracy: 0.3571 - lr: 0.0010\n",
            "Epoch 11/15\n",
            "242/242 [==============================] - 66s 273ms/step - loss: 1.2313 - accuracy: 0.4915 - val_loss: 1.4620 - val_accuracy: 0.4920 - lr: 0.0010\n",
            "Epoch 12/15\n",
            "242/242 [==============================] - 64s 264ms/step - loss: 1.1620 - accuracy: 0.5160 - val_loss: 4.0340 - val_accuracy: 0.2548 - lr: 0.0010\n",
            "Epoch 13/15\n",
            "242/242 [==============================] - 64s 263ms/step - loss: 1.1117 - accuracy: 0.5256 - val_loss: 2.5953 - val_accuracy: 0.3194 - lr: 2.0000e-04\n",
            "Epoch 14/15\n",
            "242/242 [==============================] - 66s 273ms/step - loss: 1.0600 - accuracy: 0.5341 - val_loss: 0.9585 - val_accuracy: 0.5649 - lr: 2.0000e-04\n",
            "Epoch 15/15\n",
            "242/242 [==============================] - 65s 268ms/step - loss: 1.0474 - accuracy: 0.5412 - val_loss: 0.9289 - val_accuracy: 0.5767 - lr: 2.0000e-04\n",
            "61/61 [==============================] - 3s 55ms/step - loss: 0.9289 - accuracy: 0.5767\n",
            "Test accuracy: 57.67%\n",
            "\n",
            "Training model with 3 conv layers, 128 dense neurons, dropout 0.5, learning rate 0.0005\n",
            "Epoch 1/15\n",
            "242/242 [==============================] - 66s 265ms/step - loss: 3.1257 - accuracy: 0.0991 - val_loss: 4.3418 - val_accuracy: 0.0424 - lr: 5.0000e-04\n",
            "Epoch 2/15\n",
            "242/242 [==============================] - 64s 266ms/step - loss: 2.5732 - accuracy: 0.1960 - val_loss: 2.3053 - val_accuracy: 0.2801 - lr: 5.0000e-04\n",
            "Epoch 3/15\n",
            "242/242 [==============================] - 64s 266ms/step - loss: 2.1137 - accuracy: 0.2818 - val_loss: 2.3164 - val_accuracy: 0.2884 - lr: 5.0000e-04\n",
            "Epoch 4/15\n",
            "242/242 [==============================] - 67s 276ms/step - loss: 1.8322 - accuracy: 0.3548 - val_loss: 1.5123 - val_accuracy: 0.4517 - lr: 5.0000e-04\n",
            "Epoch 5/15\n",
            "242/242 [==============================] - 64s 264ms/step - loss: 1.6247 - accuracy: 0.3987 - val_loss: 1.3410 - val_accuracy: 0.4863 - lr: 5.0000e-04\n",
            "Epoch 6/15\n",
            "242/242 [==============================] - 64s 265ms/step - loss: 1.5250 - accuracy: 0.4243 - val_loss: 1.8871 - val_accuracy: 0.4124 - lr: 5.0000e-04\n",
            "Epoch 7/15\n",
            "242/242 [==============================] - 64s 266ms/step - loss: 1.4190 - accuracy: 0.4607 - val_loss: 2.6834 - val_accuracy: 0.2910 - lr: 5.0000e-04\n",
            "Epoch 8/15\n",
            "242/242 [==============================] - 66s 274ms/step - loss: 1.3186 - accuracy: 0.4756 - val_loss: 1.7351 - val_accuracy: 0.4625 - lr: 5.0000e-04\n",
            "Epoch 9/15\n",
            "242/242 [==============================] - 66s 274ms/step - loss: 1.2752 - accuracy: 0.4857 - val_loss: 1.7972 - val_accuracy: 0.4191 - lr: 5.0000e-04\n",
            "Epoch 10/15\n",
            "242/242 [==============================] - 66s 273ms/step - loss: 1.2289 - accuracy: 0.4957 - val_loss: 2.7886 - val_accuracy: 0.3499 - lr: 5.0000e-04\n",
            "Epoch 11/15\n",
            "242/242 [==============================] - 66s 274ms/step - loss: 1.1277 - accuracy: 0.5322 - val_loss: 0.8858 - val_accuracy: 0.5835 - lr: 1.0000e-04\n",
            "Epoch 12/15\n",
            "242/242 [==============================] - 66s 272ms/step - loss: 1.1184 - accuracy: 0.5327 - val_loss: 0.9027 - val_accuracy: 0.5835 - lr: 1.0000e-04\n",
            "Epoch 13/15\n",
            "242/242 [==============================] - 64s 263ms/step - loss: 1.0748 - accuracy: 0.5360 - val_loss: 0.8556 - val_accuracy: 0.5891 - lr: 1.0000e-04\n",
            "Epoch 14/15\n",
            "242/242 [==============================] - 66s 271ms/step - loss: 1.0632 - accuracy: 0.5482 - val_loss: 0.9206 - val_accuracy: 0.5736 - lr: 1.0000e-04\n",
            "Epoch 15/15\n",
            "242/242 [==============================] - 65s 271ms/step - loss: 1.0572 - accuracy: 0.5435 - val_loss: 0.9997 - val_accuracy: 0.5690 - lr: 1.0000e-04\n",
            "61/61 [==============================] - 3s 54ms/step - loss: 0.9997 - accuracy: 0.5690\n",
            "Test accuracy: 56.90%\n",
            "\n",
            "Training model with 3 conv layers, 128 dense neurons, dropout 0.6, learning rate 0.001\n",
            "Epoch 1/15\n",
            "242/242 [==============================] - 68s 276ms/step - loss: 3.2414 - accuracy: 0.0627 - val_loss: 3.4115 - val_accuracy: 0.0506 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "242/242 [==============================] - 63s 260ms/step - loss: 2.9849 - accuracy: 0.0853 - val_loss: 2.8342 - val_accuracy: 0.1876 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "242/242 [==============================] - 66s 271ms/step - loss: 2.8507 - accuracy: 0.1134 - val_loss: 2.6913 - val_accuracy: 0.1514 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "242/242 [==============================] - 64s 263ms/step - loss: 2.6076 - accuracy: 0.1592 - val_loss: 2.1010 - val_accuracy: 0.3189 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "242/242 [==============================] - 63s 260ms/step - loss: 2.3577 - accuracy: 0.2141 - val_loss: 2.9694 - val_accuracy: 0.1917 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "242/242 [==============================] - 64s 262ms/step - loss: 2.1261 - accuracy: 0.2638 - val_loss: 18.6153 - val_accuracy: 0.0527 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "242/242 [==============================] - 63s 259ms/step - loss: 1.8942 - accuracy: 0.3224 - val_loss: 11.2927 - val_accuracy: 0.1085 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "242/242 [==============================] - 65s 269ms/step - loss: 1.7405 - accuracy: 0.3615 - val_loss: 4.5677 - val_accuracy: 0.2460 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "242/242 [==============================] - 65s 267ms/step - loss: 1.6305 - accuracy: 0.3952 - val_loss: 1.8016 - val_accuracy: 0.3804 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "242/242 [==============================] - 65s 267ms/step - loss: 1.5450 - accuracy: 0.4204 - val_loss: 2.5021 - val_accuracy: 0.3142 - lr: 0.0010\n",
            "Epoch 11/15\n",
            "242/242 [==============================] - 63s 260ms/step - loss: 1.5101 - accuracy: 0.4230 - val_loss: 1.5559 - val_accuracy: 0.4455 - lr: 0.0010\n",
            "Epoch 12/15\n",
            "242/242 [==============================] - 64s 265ms/step - loss: 1.4289 - accuracy: 0.4451 - val_loss: 6.2710 - val_accuracy: 0.1860 - lr: 0.0010\n",
            "Epoch 13/15\n",
            "242/242 [==============================] - 62s 258ms/step - loss: 1.3898 - accuracy: 0.4530 - val_loss: 12.0700 - val_accuracy: 0.2031 - lr: 0.0010\n",
            "Epoch 14/15\n",
            "242/242 [==============================] - 65s 269ms/step - loss: 1.3235 - accuracy: 0.4695 - val_loss: 7.7821 - val_accuracy: 0.1907 - lr: 0.0010\n",
            "Epoch 15/15\n",
            "242/242 [==============================] - 65s 268ms/step - loss: 1.3110 - accuracy: 0.4761 - val_loss: 9.6825 - val_accuracy: 0.1328 - lr: 0.0010\n",
            "61/61 [==============================] - 3s 56ms/step - loss: 9.6825 - accuracy: 0.1328\n",
            "Test accuracy: 13.28%\n",
            "\n",
            "Training model with 3 conv layers, 128 dense neurons, dropout 0.6, learning rate 0.0005\n",
            "Epoch 1/15\n",
            "242/242 [==============================] - 68s 270ms/step - loss: 3.2670 - accuracy: 0.0663 - val_loss: 3.6429 - val_accuracy: 0.0563 - lr: 5.0000e-04\n",
            "Epoch 2/15\n",
            "242/242 [==============================] - 63s 261ms/step - loss: 3.0447 - accuracy: 0.0771 - val_loss: 2.9354 - val_accuracy: 0.1039 - lr: 5.0000e-04\n",
            "Epoch 3/15\n",
            "242/242 [==============================] - 63s 260ms/step - loss: 2.9079 - accuracy: 0.1121 - val_loss: 2.6216 - val_accuracy: 0.1638 - lr: 5.0000e-04\n",
            "Epoch 4/15\n",
            "242/242 [==============================] - 65s 270ms/step - loss: 2.6327 - accuracy: 0.1743 - val_loss: 2.0607 - val_accuracy: 0.3220 - lr: 5.0000e-04\n",
            "Epoch 5/15\n",
            "242/242 [==============================] - 65s 270ms/step - loss: 2.3073 - accuracy: 0.2355 - val_loss: 2.7375 - val_accuracy: 0.2362 - lr: 5.0000e-04\n",
            "Epoch 6/15\n",
            "242/242 [==============================] - 65s 268ms/step - loss: 2.0678 - accuracy: 0.2867 - val_loss: 1.8773 - val_accuracy: 0.3690 - lr: 5.0000e-04\n",
            "Epoch 7/15\n",
            "242/242 [==============================] - 63s 261ms/step - loss: 1.8753 - accuracy: 0.3305 - val_loss: 2.4294 - val_accuracy: 0.3209 - lr: 5.0000e-04\n",
            "Epoch 8/15\n",
            "242/242 [==============================] - 65s 270ms/step - loss: 1.7271 - accuracy: 0.3672 - val_loss: 2.5955 - val_accuracy: 0.2599 - lr: 5.0000e-04\n",
            "Epoch 9/15\n",
            "242/242 [==============================] - 65s 268ms/step - loss: 1.6495 - accuracy: 0.3815 - val_loss: 2.0668 - val_accuracy: 0.3576 - lr: 5.0000e-04\n",
            "Epoch 10/15\n",
            "242/242 [==============================] - 65s 268ms/step - loss: 1.5562 - accuracy: 0.4049 - val_loss: 1.4534 - val_accuracy: 0.4295 - lr: 5.0000e-04\n",
            "Epoch 11/15\n",
            "242/242 [==============================] - 65s 270ms/step - loss: 1.4893 - accuracy: 0.4152 - val_loss: 5.6196 - val_accuracy: 0.2243 - lr: 5.0000e-04\n",
            "Epoch 12/15\n",
            "242/242 [==============================] - 63s 261ms/step - loss: 1.4372 - accuracy: 0.4422 - val_loss: 2.7959 - val_accuracy: 0.2842 - lr: 5.0000e-04\n",
            "Epoch 13/15\n",
            "242/242 [==============================] - 63s 261ms/step - loss: 1.3893 - accuracy: 0.4504 - val_loss: 3.2108 - val_accuracy: 0.2599 - lr: 5.0000e-04\n",
            "Epoch 14/15\n",
            "242/242 [==============================] - 65s 267ms/step - loss: 1.3167 - accuracy: 0.4650 - val_loss: 1.4217 - val_accuracy: 0.4579 - lr: 5.0000e-04\n",
            "Epoch 15/15\n",
            "242/242 [==============================] - 66s 271ms/step - loss: 1.2778 - accuracy: 0.4749 - val_loss: 5.0651 - val_accuracy: 0.1643 - lr: 5.0000e-04\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 5.0651 - accuracy: 0.1643\n",
            "Test accuracy: 16.43%\n",
            "\n",
            "Training model with 3 conv layers, 256 dense neurons, dropout 0.5, learning rate 0.001\n",
            "Epoch 1/15\n",
            "242/242 [==============================] - 68s 274ms/step - loss: 3.1530 - accuracy: 0.1072 - val_loss: 4.8241 - val_accuracy: 0.0413 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "242/242 [==============================] - 67s 276ms/step - loss: 2.3893 - accuracy: 0.2320 - val_loss: 3.2917 - val_accuracy: 0.1297 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "242/242 [==============================] - 66s 273ms/step - loss: 1.8580 - accuracy: 0.3444 - val_loss: 3.4819 - val_accuracy: 0.1943 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "242/242 [==============================] - 64s 265ms/step - loss: 1.5727 - accuracy: 0.4167 - val_loss: 3.3759 - val_accuracy: 0.2450 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "242/242 [==============================] - 66s 272ms/step - loss: 1.3935 - accuracy: 0.4563 - val_loss: 1.7105 - val_accuracy: 0.4253 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "242/242 [==============================] - 66s 273ms/step - loss: 1.3039 - accuracy: 0.4925 - val_loss: 1.3448 - val_accuracy: 0.4796 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "242/242 [==============================] - 66s 274ms/step - loss: 1.2346 - accuracy: 0.5048 - val_loss: 1.5758 - val_accuracy: 0.4057 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "242/242 [==============================] - 67s 275ms/step - loss: 1.1838 - accuracy: 0.5111 - val_loss: 3.2043 - val_accuracy: 0.3628 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "242/242 [==============================] - 65s 267ms/step - loss: 1.1470 - accuracy: 0.5256 - val_loss: 11.2127 - val_accuracy: 0.2315 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "242/242 [==============================] - 64s 266ms/step - loss: 1.1113 - accuracy: 0.5368 - val_loss: 2.5403 - val_accuracy: 0.3685 - lr: 0.0010\n",
            "Epoch 11/15\n",
            "242/242 [==============================] - 66s 275ms/step - loss: 1.0647 - accuracy: 0.5446 - val_loss: 3.3708 - val_accuracy: 0.3318 - lr: 0.0010\n",
            "Epoch 12/15\n",
            "242/242 [==============================] - 67s 275ms/step - loss: 0.9874 - accuracy: 0.5747 - val_loss: 1.0410 - val_accuracy: 0.5587 - lr: 2.0000e-04\n",
            "Epoch 13/15\n",
            "242/242 [==============================] - 65s 269ms/step - loss: 0.9474 - accuracy: 0.5753 - val_loss: 0.9375 - val_accuracy: 0.5891 - lr: 2.0000e-04\n",
            "Epoch 14/15\n",
            "242/242 [==============================] - 66s 273ms/step - loss: 0.9108 - accuracy: 0.5841 - val_loss: 1.0223 - val_accuracy: 0.5726 - lr: 2.0000e-04\n",
            "Epoch 15/15\n",
            "242/242 [==============================] - 67s 275ms/step - loss: 0.9153 - accuracy: 0.5898 - val_loss: 1.0393 - val_accuracy: 0.5271 - lr: 2.0000e-04\n",
            "61/61 [==============================] - 5s 74ms/step - loss: 1.0393 - accuracy: 0.5271\n",
            "Test accuracy: 52.71%\n",
            "\n",
            "Training model with 3 conv layers, 256 dense neurons, dropout 0.5, learning rate 0.0005\n",
            "Epoch 1/15\n",
            "242/242 [==============================] - 67s 273ms/step - loss: 3.1036 - accuracy: 0.1154 - val_loss: 5.2457 - val_accuracy: 0.0429 - lr: 5.0000e-04\n",
            "Epoch 2/15\n",
            "242/242 [==============================] - 63s 262ms/step - loss: 2.4512 - accuracy: 0.2291 - val_loss: 2.9960 - val_accuracy: 0.0827 - lr: 5.0000e-04\n",
            "Epoch 3/15\n",
            "242/242 [==============================] - 66s 271ms/step - loss: 1.9366 - accuracy: 0.3464 - val_loss: 1.3084 - val_accuracy: 0.5225 - lr: 5.0000e-04\n",
            "Epoch 4/15\n",
            "242/242 [==============================] - 64s 263ms/step - loss: 1.6273 - accuracy: 0.4074 - val_loss: 1.6112 - val_accuracy: 0.4388 - lr: 5.0000e-04\n",
            "Epoch 5/15\n",
            "242/242 [==============================] - 64s 264ms/step - loss: 1.4482 - accuracy: 0.4456 - val_loss: 1.2825 - val_accuracy: 0.4997 - lr: 5.0000e-04\n",
            "Epoch 6/15\n",
            "242/242 [==============================] - 65s 270ms/step - loss: 1.3301 - accuracy: 0.4818 - val_loss: 3.7564 - val_accuracy: 0.3023 - lr: 5.0000e-04\n",
            "Epoch 7/15\n",
            "242/242 [==============================] - 66s 273ms/step - loss: 1.2360 - accuracy: 0.5067 - val_loss: 1.0955 - val_accuracy: 0.5385 - lr: 5.0000e-04\n",
            "Epoch 8/15\n",
            "242/242 [==============================] - 64s 264ms/step - loss: 1.1481 - accuracy: 0.5230 - val_loss: 2.8364 - val_accuracy: 0.3121 - lr: 5.0000e-04\n",
            "Epoch 9/15\n",
            "242/242 [==============================] - 67s 275ms/step - loss: 1.0976 - accuracy: 0.5393 - val_loss: 2.6385 - val_accuracy: 0.3452 - lr: 5.0000e-04\n",
            "Epoch 10/15\n",
            "242/242 [==============================] - 66s 273ms/step - loss: 1.0850 - accuracy: 0.5406 - val_loss: 4.7232 - val_accuracy: 0.2873 - lr: 5.0000e-04\n",
            "Epoch 11/15\n",
            "242/242 [==============================] - 65s 270ms/step - loss: 1.0265 - accuracy: 0.5578 - val_loss: 1.0241 - val_accuracy: 0.5643 - lr: 5.0000e-04\n",
            "Epoch 12/15\n",
            "242/242 [==============================] - 66s 274ms/step - loss: 1.0107 - accuracy: 0.5554 - val_loss: 1.0640 - val_accuracy: 0.5597 - lr: 5.0000e-04\n",
            "Epoch 13/15\n",
            "242/242 [==============================] - 66s 273ms/step - loss: 0.9917 - accuracy: 0.5642 - val_loss: 1.5250 - val_accuracy: 0.5054 - lr: 5.0000e-04\n",
            "Epoch 14/15\n",
            "242/242 [==============================] - 64s 266ms/step - loss: 0.9584 - accuracy: 0.5668 - val_loss: 4.8040 - val_accuracy: 0.2801 - lr: 5.0000e-04\n",
            "Epoch 15/15\n",
            "242/242 [==============================] - 66s 274ms/step - loss: 0.9431 - accuracy: 0.5788 - val_loss: 3.1517 - val_accuracy: 0.3359 - lr: 5.0000e-04\n",
            "61/61 [==============================] - 5s 77ms/step - loss: 3.1517 - accuracy: 0.3359\n",
            "Test accuracy: 33.59%\n",
            "\n",
            "Training model with 3 conv layers, 256 dense neurons, dropout 0.6, learning rate 0.001\n",
            "Epoch 1/15\n",
            "242/242 [==============================] - 67s 271ms/step - loss: 3.3043 - accuracy: 0.0755 - val_loss: 5.1998 - val_accuracy: 0.0460 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "242/242 [==============================] - 66s 273ms/step - loss: 2.8195 - accuracy: 0.1238 - val_loss: 2.3743 - val_accuracy: 0.2548 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "242/242 [==============================] - 66s 274ms/step - loss: 2.4167 - accuracy: 0.2036 - val_loss: 4.3632 - val_accuracy: 0.0811 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "242/242 [==============================] - 64s 263ms/step - loss: 2.0944 - accuracy: 0.2819 - val_loss: 7.2599 - val_accuracy: 0.0966 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "242/242 [==============================] - 66s 273ms/step - loss: 1.8602 - accuracy: 0.3320 - val_loss: 6.9951 - val_accuracy: 0.0997 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "242/242 [==============================] - 64s 264ms/step - loss: 1.6789 - accuracy: 0.3876 - val_loss: 5.5016 - val_accuracy: 0.1695 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "242/242 [==============================] - 66s 272ms/step - loss: 1.5500 - accuracy: 0.4180 - val_loss: 3.9732 - val_accuracy: 0.1922 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "242/242 [==============================] - 66s 273ms/step - loss: 1.3748 - accuracy: 0.4590 - val_loss: 0.9383 - val_accuracy: 0.5618 - lr: 2.0000e-04\n",
            "Epoch 9/15\n",
            "242/242 [==============================] - 65s 267ms/step - loss: 1.3293 - accuracy: 0.4709 - val_loss: 2.0841 - val_accuracy: 0.3742 - lr: 2.0000e-04\n",
            "Epoch 10/15\n",
            "242/242 [==============================] - 64s 265ms/step - loss: 1.2811 - accuracy: 0.4831 - val_loss: 3.8903 - val_accuracy: 0.2413 - lr: 2.0000e-04\n",
            "Epoch 11/15\n",
            "242/242 [==============================] - 65s 270ms/step - loss: 1.2329 - accuracy: 0.4968 - val_loss: 1.6203 - val_accuracy: 0.4481 - lr: 2.0000e-04\n",
            "Epoch 12/15\n",
            "242/242 [==============================] - 66s 273ms/step - loss: 1.2172 - accuracy: 0.4966 - val_loss: 1.4679 - val_accuracy: 0.4853 - lr: 2.0000e-04\n",
            "Epoch 13/15\n",
            "242/242 [==============================] - 66s 273ms/step - loss: 1.1878 - accuracy: 0.5049 - val_loss: 3.2799 - val_accuracy: 0.3085 - lr: 2.0000e-04\n",
            "Epoch 14/15\n",
            "242/242 [==============================] - 64s 265ms/step - loss: 1.1608 - accuracy: 0.5128 - val_loss: 0.8787 - val_accuracy: 0.5804 - lr: 1.0000e-04\n",
            "Epoch 15/15\n",
            "242/242 [==============================] - 64s 263ms/step - loss: 1.1514 - accuracy: 0.5172 - val_loss: 1.5680 - val_accuracy: 0.4703 - lr: 1.0000e-04\n",
            "61/61 [==============================] - 4s 58ms/step - loss: 1.5680 - accuracy: 0.4703\n",
            "Test accuracy: 47.03%\n",
            "\n",
            "Training model with 3 conv layers, 256 dense neurons, dropout 0.6, learning rate 0.0005\n",
            "Epoch 1/15\n",
            "242/242 [==============================] - 67s 268ms/step - loss: 3.2426 - accuracy: 0.0965 - val_loss: 4.3261 - val_accuracy: 0.0455 - lr: 5.0000e-04\n",
            "Epoch 2/15\n",
            "242/242 [==============================] - 64s 265ms/step - loss: 2.7132 - accuracy: 0.1660 - val_loss: 2.4109 - val_accuracy: 0.2289 - lr: 5.0000e-04\n",
            "Epoch 3/15\n",
            "242/242 [==============================] - 64s 266ms/step - loss: 2.2625 - accuracy: 0.2672 - val_loss: 2.3636 - val_accuracy: 0.2682 - lr: 5.0000e-04\n",
            "Epoch 4/15\n",
            "242/242 [==============================] - 65s 270ms/step - loss: 1.9059 - accuracy: 0.3494 - val_loss: 1.9698 - val_accuracy: 0.3271 - lr: 5.0000e-04\n",
            "Epoch 5/15\n",
            "242/242 [==============================] - 65s 267ms/step - loss: 1.6553 - accuracy: 0.4008 - val_loss: 1.8533 - val_accuracy: 0.3793 - lr: 5.0000e-04\n",
            "Epoch 6/15\n",
            "242/242 [==============================] - 65s 271ms/step - loss: 1.4874 - accuracy: 0.4289 - val_loss: 1.6067 - val_accuracy: 0.4284 - lr: 5.0000e-04\n",
            "Epoch 7/15\n",
            "242/242 [==============================] - 66s 274ms/step - loss: 1.4056 - accuracy: 0.4623 - val_loss: 2.1540 - val_accuracy: 0.3612 - lr: 5.0000e-04\n",
            "Epoch 8/15\n",
            "242/242 [==============================] - 64s 266ms/step - loss: 1.3218 - accuracy: 0.4792 - val_loss: 1.1217 - val_accuracy: 0.5313 - lr: 5.0000e-04\n",
            "Epoch 9/15\n",
            "242/242 [==============================] - 66s 272ms/step - loss: 1.2556 - accuracy: 0.5049 - val_loss: 4.2214 - val_accuracy: 0.2827 - lr: 5.0000e-04\n",
            "Epoch 10/15\n",
            "242/242 [==============================] - 64s 266ms/step - loss: 1.1588 - accuracy: 0.5211 - val_loss: 1.8978 - val_accuracy: 0.4558 - lr: 5.0000e-04\n",
            "Epoch 11/15\n",
            "242/242 [==============================] - 64s 264ms/step - loss: 1.1769 - accuracy: 0.5156 - val_loss: 1.6145 - val_accuracy: 0.4775 - lr: 5.0000e-04\n",
            "Epoch 12/15\n",
            "242/242 [==============================] - 66s 274ms/step - loss: 1.1029 - accuracy: 0.5384 - val_loss: 1.5549 - val_accuracy: 0.4775 - lr: 5.0000e-04\n",
            "Epoch 13/15\n",
            "242/242 [==============================] - 66s 274ms/step - loss: 1.0934 - accuracy: 0.5439 - val_loss: 1.9713 - val_accuracy: 0.4336 - lr: 5.0000e-04\n",
            "Epoch 14/15\n",
            "242/242 [==============================] - 66s 272ms/step - loss: 1.0374 - accuracy: 0.5527 - val_loss: 2.9198 - val_accuracy: 0.3499 - lr: 1.0000e-04\n",
            "Epoch 15/15\n",
            "242/242 [==============================] - 64s 263ms/step - loss: 0.9758 - accuracy: 0.5643 - val_loss: 1.0867 - val_accuracy: 0.5442 - lr: 1.0000e-04\n",
            "61/61 [==============================] - 3s 56ms/step - loss: 1.0867 - accuracy: 0.5442\n",
            "Test accuracy: 54.42%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#model 3\n",
        "\n",
        "def build_model(conv_layers, dense_neurons, dropout_rate, learning_rate):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "    for _ in range(conv_layers - 1):  # Adding more convolutional layers based on the parameter\n",
        "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(MaxPooling2D(2, 2))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(dense_neurons, activation='relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(len(categorical_labels[0]), activation='softmax'))\n",
        "\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Example of using the build_model function\n",
        "model = build_model(conv_layers=3, dense_neurons=128, dropout_rate=0.5, learning_rate=0.001)\n",
        "# Initialize data generator for augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "datagen.fit(X_train)\n",
        "\n",
        "# Callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
        "\n",
        "# Testing different hyperparameters\n",
        "conv_layers_options = [2, 3]\n",
        "dense_neurons_options = [128, 256]\n",
        "dropout_options = [0.5, 0.6]\n",
        "learning_rates = [0.001, 0.0005]\n",
        "\n",
        "for conv_layers in conv_layers_options:\n",
        "    for dense_neurons in dense_neurons_options:\n",
        "        for dropout_rate in dropout_options:\n",
        "            for lr in learning_rates:\n",
        "                model = build_model(conv_layers, dense_neurons, dropout_rate, lr)\n",
        "                print(f\"Training model with {conv_layers} conv layers, {dense_neurons} dense neurons, dropout {dropout_rate}, learning rate {lr}\")\n",
        "                model.fit(\n",
        "                    datagen.flow(X_train, y_train, batch_size=32),\n",
        "                    epochs=15,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    callbacks=[reduce_lr, early_stopping]\n",
        "                )\n",
        "                loss, accuracy = model.evaluate(X_test, y_test)\n",
        "                print(f\"Test accuracy: {accuracy * 100:.2f}%\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woN4Bkta5xul",
        "outputId": "f4480712-e38a-4529-b3fc-c4324e6fdbdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "242/242 [==============================] - 62s 249ms/step - loss: 3.1621 - accuracy: 0.0472 - val_loss: 3.1490 - val_accuracy: 0.0543 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "242/242 [==============================] - 58s 241ms/step - loss: 3.1473 - accuracy: 0.0451 - val_loss: 3.1408 - val_accuracy: 0.0543 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "242/242 [==============================] - 58s 238ms/step - loss: 3.1388 - accuracy: 0.0504 - val_loss: 3.1306 - val_accuracy: 0.0543 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "242/242 [==============================] - 58s 239ms/step - loss: 3.1239 - accuracy: 0.0495 - val_loss: 3.0733 - val_accuracy: 0.0543 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "242/242 [==============================] - 58s 239ms/step - loss: 3.0663 - accuracy: 0.0669 - val_loss: 2.9272 - val_accuracy: 0.0651 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "242/242 [==============================] - 59s 244ms/step - loss: 2.9814 - accuracy: 0.0807 - val_loss: 2.8449 - val_accuracy: 0.1096 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "242/242 [==============================] - 59s 246ms/step - loss: 2.9145 - accuracy: 0.0913 - val_loss: 2.7720 - val_accuracy: 0.1282 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "242/242 [==============================] - 56s 233ms/step - loss: 2.8553 - accuracy: 0.0963 - val_loss: 2.6876 - val_accuracy: 0.1488 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "242/242 [==============================] - 59s 244ms/step - loss: 2.7828 - accuracy: 0.1114 - val_loss: 2.5964 - val_accuracy: 0.1752 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "242/242 [==============================] - 59s 244ms/step - loss: 2.7104 - accuracy: 0.1264 - val_loss: 2.4131 - val_accuracy: 0.1928 - lr: 0.0010\n",
            "61/61 [==============================] - 3s 47ms/step - loss: 2.4131 - accuracy: 0.1928\n",
            "Test accuracy: 19.28%\n"
          ]
        }
      ],
      "source": [
        "#model 4 with shuffle\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 1), kernel_regularizer=l2(0.0001)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    SpatialDropout2D(0.1),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.0001)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    SpatialDropout2D(0.1),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.0001)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    SpatialDropout2D(0.1),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu', kernel_regularizer=l2(0.0001)),\n",
        "    Dropout(0.9),\n",
        "    Dense(len(categorical_labels[0]), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
        "\n",
        "# Train the model using the augmented data generator\n",
        "model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=32),\n",
        "    epochs=10,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[reduce_lr, early_stopping]\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
